<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>58同城AILab面经</title>
    <url>/2019/06/05/58%E5%90%8C%E5%9F%8EAILab%E9%9D%A2%E7%BB%8F/</url>
    <content><![CDATA[<p>​    这些都是一个星期面的，感觉头皮发麻。。。</p>
<p><strong>叭咔科技</strong></p>
<p>​    先写在这里，因为是交叉在里面的</p>
<p>​    一次性面了两面+hr面，整体上技术面比较水，但是有一道题目挺有意思的，记录一下。让你通过什么方法去近似求一下圆形的面积，当时我一脸蒙b，后来面试官提示说可以从概率的角度，用随机数什么的，才想出了用变长为2r的正方形去处理</p>
<p>​    这里涉及到一个列表和链表在增删时处理冲突的问题，列表可能会出现寻址问题</p>
<p>​    其中还有一个尴尬的问题是<strong>python中random.random生成的随机数是</strong>均匀分布还是正态分布？答案是<strong>均匀分布</strong></p>
<hr>
<p><strong>58同城</strong></p>
<p>一面</p>
<p>​    这一面面试官人很nice而且感觉专业水平很强，从我说项目开始一直问的模型问题都很深，问题面也边角广，而且注重细节，还会问一些具体模型实现上的事情，比如说transformer中的muti-self attention在编码上是如何实现的？word2vec输入一个词时是只更新一个词还是会更新全部的词？整体上感觉答的还可以就进了二面。然后让写了一道算法题，再两个无序数组中找出全部和为定值的组合，这个题我直接和他说了暴力枚举，他说你这个时间是多少？还能不能再优化一下？我说是O(n2)，他说能不能优化到O(n)？我说那就可以将第一数组先转成字典，这样可以降到O(n)</p>
<p>二面</p>
<p>​    二面整体来说比一面要简单一些，主要就是问项目上事情，特征、数据处理、模型效果等等，涉及到模型具体实现细节上的东西没有深问，本来以为一定会深问transformer的，然而并没有提。。。</p>
<p>三面</p>
<p>​    刚面完，热乎的三面，主要问的问题还是比较简单了，没有一面的难，感觉也是个技术人员，但是没有问的很深，遇到了一个和一面一样的问题，pytorch和tensorflow的区别在哪里，其他的基本上和一面一样了，讲项目、word2vec的原理、优化，正则化原理、公式，auc、roc含义是怎么来的，有一个问题没有答出来，kmeans是否一定会收敛，为什么？</p>
<p>good luck！</p>
<p>顺利通过，在端午回家的前一天顺利上岸，happy！</p>
<hr>
<p><strong>微软亚洲研究院</strong></p>
<p>一面</p>
<p>​    项目介绍+算法题，去除数组中重复元素去重，写完了又加了一条，删除数组中有重复元素的数</p>
<p>一面面完已经过了4、5天了，还没约面试时间，一面感觉还不错，不知道为什么就凉了。。。</p>
<hr>
<p><strong>深信服</strong></p>
<p>HR说面试时间已经约了，他说下周，但是下周已经过了三天，还会没消息   希望过完端午回去可以有机会</p>
]]></content>
      <tags>
        <tag>面经</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里2019年最新论文-定位然后检测恶意攻击</title>
    <url>/2019/09/04/%E9%98%BF%E9%87%8C2019%E5%B9%B4%E6%9C%80%E6%96%B0%E8%AE%BA%E6%96%87-%E5%AE%9A%E4%BD%8D%E7%84%B6%E5%90%8E%E6%A3%80%E6%B5%8B%E6%81%B6%E6%84%8F%E6%94%BB%E5%87%BB/</url>
    <content><![CDATA[<p>论文名称:《Locate-Then-Detect: Real-time Web Attack Detection via Attention-based<br>Deep Neural Networks》</p>
<p>主要针对的攻击类型:sql、xss</p>
<p>采用的方式:先定位攻击载荷在进行恶意检测</p>
<p>内容解读：</p>
<p>​    主要分为两阶段网络</p>
<blockquote>
<p>PLN(Payload Locat-ing Network):在整个url、post中定位到关键部分，去掉无用信息</p>
<p>PCN(Payload Classification Network):利用PLN网络得到的关注度信息进行分类</p>
</blockquote>
<h2 id="PLN"><a href="#PLN" class="headerlink" title="PLN"></a>PLN</h2><p>​    <strong>目标</strong>：</p>
<p>​    <strong>输入</strong>:固定长度的请求输入文本</p>
<p>​    <strong>输出:</strong>区域位置和可疑置信度</p>
<p>​    <strong>核心思想</strong>：图像分割的思想</p>
<blockquote>
<p>PLN网络要进行单独的训练，然后加到PCN网络之前，固定参数值(我的理解)</p>
</blockquote>
<h4 id="request请求编码"><a href="#request请求编码" class="headerlink" title="request请求编码"></a>request请求编码</h4><p>​    首先设置一个最大长度L，然后进行字符级别的embedding，即每个字符都转化成一个对应的k维Embbeding向量，最终输出为：L*K维向量</p>
<blockquote>
<p>这里的最大长度法和我们之前的方法类似，直接进行长度限制，忽略了在超长的正常参数尾部追加恶意payload形式的攻击    </p>
</blockquote>
<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><p>​    模型：Xception</p>
<blockquote>
<p>Xception模型</p>
<p>​    先进行普通卷积操作，再对 1×1 卷积后的每个channel分别进行 3×3 卷积操作，最后将结果 concat</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/Xception模型.png?raw=true" alt></p>
</blockquote>
<p>​    加速计算：thin feature maps with small channel(不损失很大精度的前提下显著提升速度)</p>
<h4 id="模型部分"><a href="#模型部分" class="headerlink" title="模型部分"></a>模型部分</h4><p>​    沿着特征图滑动几个mini-networks来检测可以片段，该网络采样特征图一个n<em>m的窗口，在mini-network层之后经过两个1\</em>m并列的层——区域回归层和区域分类层</p>
<blockquote>
<p>为了保证保持嵌入张量中这些向量的语义完整性，我们令m等于字符向量的嵌入大小。</p>
</blockquote>
<p>reg层输出坐标：(p,2p)有效载荷的开始位置和结束位置</p>
<p>cls层：输出每个区域的得分</p>
<p>对于输入特征图为W<em>H的，将会有H\</em>P个区域</p>
<p>并不是所有区域都是有效的，</p>
<h5 id="区域的标注"><a href="#区域的标注" class="headerlink" title="区域的标注"></a>区域的标注</h5><p>区域标注为积极标签的方法为:</p>
<blockquote>
<p>1.将用于最大的交集序列（Ios）的区域标为积极</p>
<p>2.将交集序列的值（Ios）大于0.5的值定位积极</p>
</blockquote>
<p>区域标注为消极标签:</p>
<blockquote>
<p>将交集序列的值小于0.2的标为消极序列</p>
</blockquote>
<p>​    如果既没有标为消极也没有标为积极，那么则忽略该区域。一般情况下消极区域的数量远大于积极区域，如果消极区域和积极区域的比例大于3：1，那么将其归置到3：1。</p>
<h5 id="PLN层的损失函数："><a href="#PLN层的损失函数：" class="headerlink" title="PLN层的损失函数："></a>PLN层的损失函数：</h5><p><img src="https://github.com/AnchoretY/images/blob/master/blog/PLN损失函数.png?raw=true" alt></p>
<p>​    参数意义：</p>
<blockquote>
<p>i：区域的编号</p>
<p>li:区域的label，积极区域为1，否则为0</p>
<p>posi、pos∗i :分别代表了区域的开始位置和结束位置</p>
<p>Lcls：是区域的分类对数损失函数，</p>
<p>Lreg: 是积极区域的回归损失函数，不关注负样本，该回归损失函数采用：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/smooth-L1损失函数.png?raw=true" alt> </p>
<p>​    x表示区域真实标签和预测值之间的差距</p>
<p>λ：控制损失函数的前后两个部分的重要性，本文中采用的是1.0</p>
<p>Ncls: 本文中设置为mini-batch 大小</p>
<p>Nreg:本文设置为区域个数，</p>
</blockquote>
<h4 id="数据标注"><a href="#数据标注" class="headerlink" title="数据标注"></a>数据标注</h4><p>​    在整个LTD模型结构中，需要大量的标注数据，本文提出了基于HMM的异常检测系统来辅助序列标注，该系统通过大量的HMM模型来实现，每个host的每个url的参数值都会训练一个hmm模型，检测到的异常参数经过规则检测系统确定为xss或sql会标记起始和结束位置。</p>
<p>​    <strong>作用:表示有效payload位置</strong></p>
<p>​    <strong>方法：参数hmm+规则系统</strong></p>
<blockquote>
<p>实例：</p>
<p>​    uri1 = /a.php?id=1&amp;name=1’ and 1=1</p>
<p>首先提取各个参数的值，得到</p>
<p>​    {val1 : 1, val2 : 1′ and 1 = 1}</p>
<p>使用hmm参数异常检测模型确定是否存在异常参数值</p>
<p>​    val2是异常的参数值</p>
<p>使用规则模型判别该参数为sql注入，定位位置，标记异常区域</p>
<p>​     [Start (17), End (27), Label (1)]</p>
</blockquote>
<h2 id="PCN"><a href="#PCN" class="headerlink" title="PCN"></a>PCN</h2><p>​    目标:对PLN层定位的可疑区域，在PCN部分进行深入的分析，找到攻击的区域，</p>
<p>​    输入：PLN中得分最高的三个区域(最可疑)</p>
<p>​    输出: 是否为攻击以及攻击类型</p>
<p>​    核心思想：采用CNN进行文本分类</p>
<h4 id="具体做法"><a href="#具体做法" class="headerlink" title="具体做法"></a>具体做法</h4><blockquote>
<p>采用5层不同大小的卷积核，并且每个卷积核后都会带一个max-overtime pooling operation ，不同的卷积核大小保证了PCN能够精确地识别具有多种特征的攻击。这些特征被连接起来，在连接在层线性层，最后使用softmax输出是各种攻击的可能性</p>
</blockquote>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>​    PCN部分的损失函数就是标准的交叉熵损失函数加上一个L1正则化项：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/PCN.png?raw=true" alt></p>
<p>该层主要是一个文本分类的层，和PCN层共享相同的Embedding向量，输出给定区域是否为恶意以及攻击类型</p>
<h3 id="数据产生方法"><a href="#数据产生方法" class="headerlink" title="数据产生方法"></a>数据产生方法</h3><blockquote>
<p>1.首先使用传统的WAF找出正常流量</p>
<p>2.构造sql、xss的payload参数值随机换到正常流量的参数值部分</p>
</blockquote>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="1-CSCI"><a href="#1-CSCI" class="headerlink" title="1.CSCI"></a>1.CSCI</h4><p>​    CSCI 2010数据集包含针对电子商务Web应用程序生成的流量，该数据集包含25,000多个异常请求和36,000个良性请求，使用其中2,072 SQLi和1,502 XSS样本作为黑样本，其他的正常流量和攻击流量统一标记为白样本。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/CSCI数据集实验对比.png?raw=true" alt></p>
<p>​    LTD与RWAF相比，在精确率吧和召回率方面均要好。LTD和Libinjection都具有100%的精确率，但是LTD拥有更高的召回率。</p>
<h4 id="2-真实流量"><a href="#2-真实流量" class="headerlink" title="2.真实流量"></a>2.真实流量</h4><p>数据来源</p>
<p>​    300w条真实流量数据，其中包括38600个sql注入和xss攻击实例。    </p>
<h4 id="Part-1-模型优越性的证明"><a href="#Part-1-模型优越性的证明" class="headerlink" title="Part 1  模型优越性的证明"></a>Part 1  模型优越性的证明</h4><p><img src="https://github.com/AnchoretY/images/blob/master/blog/真实流量实验结果对比.png?raw=true" alt></p>
<p>​    其中，</p>
<p>​    <strong>1.LTD获得了最高的精确率，HMM-Web获得了最高的召回率，但是它的误报率过高</strong>，在在真实的WAF应用中，误报率必须少于0.01%。</p>
<p>​    <strong>分析：</strong>在该实验中，HMM-Web方式之所以比LTD获得了更加高的准确率，是因为HMM-Web所采用的方式是基于异常检测的方式，只要是之前没有见过的流量都会被判别为恶意。但这种HMM异常检测的缺陷也非常的明显，每当有系统更新时，HMM-web模型都需要重新进行训练，因此HMM-web并不是一个很好的实时web入侵检测方式。</p>
<blockquote>
<p>对于对于Web攻击检测，在误报和召回之间存在权衡，而低误报是生产环境中的先决条件。因为高误报会造成用户正常访问的阻塞</p>
</blockquote>
<p>​    <strong>2.Libinjection和LTD都获得了100%的精确率，但LTD的召回率达到了99.8%，而Libinjection只有71%。</strong>下面是一些Libinjection误分类而LTD分类正确分类的样本：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/Libinjection和LTD评判结果比较.png?raw=true" alt></p>
<p>​    <strong>分析：</strong>这里的解释有点没太看懂，好像有点和上表对不上，大致意思是说Libinjection过分依赖指纹库，进行微小的改变都很难进行检测，而且由于有些正常流量可能偶尔也会出现指纹库中的部分内容，因此很容易误报</p>
<p>​    <strong>3.LTD比RWAF方式准确率和召回率都好。</strong></p>
<h4 id="Part2-PLN部分有效性的证明"><a href="#Part2-PLN部分有效性的证明" class="headerlink" title="Part2 PLN部分有效性的证明"></a>Part2 PLN部分有效性的证明</h4><p>实验组1：LTD</p>
<p>实验组2 ：VPCN,把url参数部分却分为key-value形式，LTD去掉PLN部分只留下PCN部分进行分类</p>
<p><em>个人看法：这里我个人觉得对比试验有点问题，因为直接用PCN部分进行分类不一定非要进行参数切分，因此这里使用切与不切分进行对比，证明LTD效率更高个人认为不成立，应该使用直接使用PCN进行对原始embedding后的内容进行分类</em></p>
<h5 id="1-效率上"><a href="#1-效率上" class="headerlink" title="1.效率上"></a>1.效率上</h5><p><img src="https://github.com/AnchoretY/images/blob/master/blog/PLN效率增强实验.png?raw=true" alt>    </p>
<p>​    在有GPU的的环境下，带PLN的网络比不带的快6倍，没有GPU的环境下快了8倍。</p>
<p>​    分析：LTD之所以效率高的多是因为不使用PLN，直接参数个数过多，27.5的Url有13个参数以上，切分参数需要花费大量的时间，在真实流量中，包含参数个数可能更多。另一方面，一些开发者因为某些原因重新模块来隐藏参数，在这种情况下，基于规则的计算需要更加复杂的计算来提取该值。<strong>与传统的方法相比，LTD通过限制检测区域来加快计算效率，另一方面也避免了参数重写造成的切割效率问题</strong></p>
<h5 id="2-准确率"><a href="#2-准确率" class="headerlink" title="2.准确率"></a>2.准确率</h5><p>​    <strong>对照组</strong>：典型的char级cnn从原始请求进行分类</p>
<p>​    数据集来源：</p>
<p>​        训练集：真实流量中320w正常流量，80w攻击样本</p>
<p>​        测试数据集：10w条不同时间的正常流量数据，在其中选择10000个样本随机将其中一个参数的值替换为SQLi、XSS的攻击载荷，形成恶意样本，其他的为正常样本</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/LTD和charcnn对比.png?raw=true" alt></p>
<p>​    经过实验，明显可以看出，<strong>直接的CNN的误报率和漏报率比LTD都要高得多</strong>，而这时因为一般payload的长度都很短，而url请求的长度很长。某些已知攻击的payload长度最短可以为6个字符，而这些很短的payload就可以隐藏在很长的背景字符串之中，导致CNN很难学到恶意payload，而LTD中的PLN模块能通过过滤不相关部分来发现隐藏在很长背景字符串中的短payload，因此，LTD可以更准确地区分实际的攻击有效负载和那些恶意的良性URL片段。</p>
<h5 id="Part3-PLN输出可疑区域个数选择"><a href="#Part3-PLN输出可疑区域个数选择" class="headerlink" title="Part3 PLN输出可疑区域个数选择"></a>Part3 PLN输出可疑区域个数选择</h5><p>​    分别绘制了xss、sql在1~5个可以区域的ROC、PR曲线，如下：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/PLN可疑区域个数选择.png?raw=true" alt></p>
<p>​    <strong>当区域数为3时，SQLi和XSS均达到了最好或者非常接近最好的准确率</strong>。使用更多的区域数能够获得更好的召回率，但是误报率将大大升高。</p>
<h3 id="依然存在的问题"><a href="#依然存在的问题" class="headerlink" title="依然存在的问题"></a>依然存在的问题</h3><p>​    1.限定输入长度，对于特长的尾部追加式的攻击依然没有识别能力</p>
<p>​    2.单纯的在SQLi和XSS上进行实验，未来还需要文件包含和代码执行等其他攻击类型进行检测</p>
<p>​    3.所谓的提升了可解释性我觉得并没有很好地可以追溯源头</p>
<p>【1】Hmm-web: A framework for the detection of attacks against web applications</p>
<p>【2】Xception:Deep learning with depthwise separable convolutions.</p>
<p>【3】Detection of sql injection attacks using hidden markov model.</p>
<p> 【4】Character-aware neural language models.</p>
<p>【5】A method for stochastic optimization</p>
<p>【6】 Light-head r-cnn: In defense of two-stage object detector.</p>
<p>【7】Application of the generic feature selection measure in detection of web attacks</p>
<p>【8】Ef-ficient character-level document classification by combining convolution and recurrent layers</p>
<p>貌似</p>
]]></content>
      <tags>
        <tag>安全</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
</search>
