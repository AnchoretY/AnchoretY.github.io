---
title: 面试常见的大数据相关问题
date: 2019-08-14 15:19:28
tags: [面试]
---

### 经典题目

##### 1、海量日志数据，提取出某日访问百度次数最多的那个IP。

> 分析:IP的数目还是有限的，共2^32个，因此可以直接进行hash map
>
> 解决方案:
>
> ​	首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。

##### 2.有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

> 

##### 3.有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

> 方案：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。
>
> 　　如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。



##### 4.给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

> 方案1：
>
> ​	可以估计每个文件的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。
>
> 　　遍历文件a，**对每个url求取hash(url)%1000**，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。
>
> 　　遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
>
> 　　求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。

##### 5.在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

> 方案1：
>
> ​	采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

1.10M内存完成一个100G文件的排序

>利用内存和硬盘共同进行排序，每个内存

2.高考满分750，有100w个考生的成绩，求第一百名的成绩（要求最优）。

> 使用字典，桶排序





### 海量数据处理题目常用方法

#### 1.Hashing

​	适用范围：快速查找，删除的基本数据结构，通常需要总数据量可以放入内存

**问题实例：**

> （1).海量日志数据，提取出某日访问百度次数最多的那个IP(经典题目一)。

#### 2.bit-map

​	适用范围：可进行数据的快速查找，判重，删除，一般来说**数据范围是int的10倍以下**

​	基本原理及要点：使用bit数组来表示某些元素是否存在，比如8位电话号码

**问题实例：**

> 1)已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。
>
> 　　8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。
>
> 2)2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。
>
> 　　将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。

#### 3.堆

​	适用范围：海量数据前n大，并且n比较小，堆可以放入内存

​	基本原理及要点：最大堆求前n小，最小堆求前n大。方法，比如求前n小，我们比较当前元素与最大堆里的最大元素，如果它小于最大元素，则应该替换那个最大元素。这样最后得到的n个元素就是最小的n个。适合大数据量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。

**问题实例：**

>  1)100w个数中找最大的前100个数。
>
> ​	用一个100个元素大小的最小堆即可。

#### 4.外排序

​	适用范围：大数据的排序，去重

　基本原理及要点：外排序的归并方法，置换选择败者树原理，最优归并树

**问题实例**

> 1) 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。
>
> 分析:因为是计算频数，因此肯定没有办法用位图法，然后考虑是否能用hashing法，内存限制仅为1M，因此也不行，因此考虑外排序法。
>
> 方案：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。
>
> 　　如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。



#### trie树



**问题实例：**

> 　1).有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。
>
> 
>
> 　2).1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？
>
> 
>
> 　3).寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。　　
>
> 第一步、先对这批海量数据预处理，在O（N）的时间内用Hash表完成排序；然后，第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。 即，借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比所以，我们最终的时间复杂度是：O（N） + N'*O（logK），（N为1000万，N’为300万

　