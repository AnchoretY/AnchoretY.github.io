---
title: 目标检测——常见目标检测算法
date: 2019-10-27 15:02:34
tags: [深度学习,目标检测,图像]
---

&emsp;&emsp;本文从整体上对目标检测算法做了概述，首先对目前目标检测算法的主要流派做阐述，然后针对传统目标检测算法以及新兴的候选区域+深度学习方式两种方式的主流目标检测算法分别做比较详细介绍。

![image](https://raw.githubusercontent.com/AnchoretY/images/master/blog/image.12zbhb158on.png)

<!--more-->

### 

### 1.回归+分类双头网络

&emsp;&emsp;将问题看做回归问题，预测出方框的坐标值。

&emsp;&emsp;**基本的处理流程**

**1.先搭建一个图像识别任务的卷积神经网络(CNN+full connected)**

​	![](https://github.com/AnchoretY/images/blob/master/blog/标准图像识别卷积神经网络.png?raw=true)

**2.将上面搭建好的卷积神经网络进行的尾部与全连接分类网络并行的加入一个新的回归分类网络，形成classfication+regession模式**

![](https://github.com/AnchoretY/images/blob/master/blog/分类回归型卷积神经网络.png?raw=true)

**3.加入回归头后对regession部分采用欧式距离损失使用SGD进行训练**

{%note info%}

由于regession很难进行训练，因此网络采取classfication的网络来计算出classfication head和regression head的共同的连接权值，然后前面的部分保持参数不变，只训练regession head部分的连接的权值(这里是第一次fine-tune)

{%endnote%}

**4.预测阶段，两个头同时完成图像识别和定位的工作**



### 2.候选区域+深度学习

#### two-stage模型

&emsp;&emsp;two-stage模型与传统的目标检测算法、人们的认知方式比较接近，即首先采用

#### (一) R-CNN

​	**R-CNN模型即使用Region Proposal + CNN**代替传统目标检测使用的滑动窗口+手工设计特征，首先在途中找出目标可能会出现的位置，即候选区域(Region Proposal)，可以保证在选取较少（几千甚至几百）的窗口的前提下保持较高的召回率。核心包括：

>  1.区域选择算法
>
> ​	常见的选择性搜索算法主要有Selective Search[]()和EdgeBoxs。
>
> 2.CNN特征提取网络
>
>  
>
> 3.

 ![](https://github.com/AnchoretY/images/blob/master/blog/R-CNN结构图.png?raw=true)

##### R-CNN整体流程

​	1.输入测试图像

​	2.利用Selective Search算法从图像中从下到上提取2000个左右的可能包含物体的候选区域(各个候选区域的大小可能不同)，将各个候选区域缩放成统一的大小并输入到CNN网络中进行特征提取。

​	3.将CNN网络中提取到的特征输入到SVM中进行分类

##### R-CNN具体步骤

> **1.首先训练一个分类模型。**
>
> ​	例如训练一个TextCNN模型
>
> **2.对该模型做finue-tuning**
>
> ​	去除原有全连接层
>
> **3.候选框选择**
>
> ​	使用Selective Search算法进行候选框选择
>
> **4.对于每一个候选区域大小进行修正（统一大小）输入到前面训练好的CNN网络中，做一次前向运算，将卷积层提取到的特征存储到硬盘。**
>
> **5.使用第四步存储的各个候选框的特征训练一个SVM模型**，来判断去区域中的物体是否为该类
>
> **6.使用回归器调整候选框位置。**
>
> ​	对于每一个类，训练一个线性回归模型去判定这个框是否框得完美。
>
> ![](https://github.com/AnchoretY/images/blob/master/blog/回归器精修.png?raw=true)

##### R-CNN存在的问题

> ​	对原始图片**通过Selective Search提取的候选框region proposal多达2000个**左右，而这2000个候选框**每个框都需要进行CNN提特征+SVM分类，计算量很大**

​	

#### (二) SSP Net

​	SSP Net全称Spatial Pyramid Pooling Net（空间金字塔池化网络）

##### 1.主要改进点

> **1.提出ROI池化层。**
>
> ​	可以保证不同大小的输入到CNN部分，输出大小相同的向量可以直接输入到一个全连接网络。
>
> **2.只对原图进行一次卷积特征提取。**
>
> 

##### 2.ROI池化层

​	众所周知，CNN一般都含有卷积部分和全连接部分，其中，卷积层不需要固定尺寸的图像，而全连接层是需要固定大小的输入。所以一般在不同大小的数据输入到全连接网络之前一般都需要对数据进行crop（切割）或者warp(增大)到同一尺寸，才能输入到CNN网络中，但是采用这种处理方式将会到导致的问题是要么拉伸变形、要么数据不全，大大影响了识别的准确率。

​	既然由于全连接FC层的存在，**普通的CNN需要通过固定输入图片的大小来使得全连接层的输入固定。那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使使得后面全连接层得到的输入变成固定的呢**？

>作用:**使CNN网络的输入可以是任意尺度的**，在SPP layer中每一个pooling的filter会**根据输入调整大小，而SPP的输出则是固定维数的向量，然后给到全连接FC层。**

**具体流程**

![](https://github.com/AnchoretY/images/blob/master/blog/ROI结构图.png?raw=true)

> 假设输入ROI Pooling层的feature map of conv5的shape是(h,w,c)
>
> 1. 首先ROI Pooling层把feature map of conv5划分成4*4的小方块(对应图中蓝色矩形),每个小方块的宽高分别为w/4,h/4,通道数为c,不能整除时需要取整.针对feature map的每个通道,分别在这16个小方块进行最大池化(MaxPooling),也就是取出小方块里的最大值.每一个通道都能取出16个最大值,所以所有通道共有16c个值
> 2. 然后ROI Pooling层把feature map of conv5划分成2*2的小方块(对应图中绿色矩形),使用同样的方法得到4c个值
> 3. 接着ROI Pooling层把feature map of conv5划分成1*1的小方块(对应图中灰色矩形),得到c个值
> 4. 最后将上面三个值串联起来得到长度为16c+4c+c=21c的特征表示





##### 3.只对原图进行一次卷积

​	针对R-CNN中每个候选框都要单独输入到CNN中，这样做十分低效的缺陷，SSP Net针对这个缺陷做了优化：

​	**只对原图进行一次卷积运算，得到整张图的feature map，然后找到每个候选框在 feature map上的映射的patch，然后将每个候选框对应的patch卷积特征输入到SSP layer之后的层，完成特征提取工作。**

> 速度比R-CNN方式提升了100倍



#### (三) Fast R-CNN

​	Fast R-CNN的实质就是在R-CNN的基础上增加了SSP Net的方法

![](https://github.com/AnchoretY/images/blob/master/blog/Fast_R-CNN结构图.png?raw=true)

与R-CNN框架相比的完善点：

> 1.卷积层后面加入了一个ROI Pooling层
>
> 2.损失函数使用了多任务损失函数，将边框回归直接加入到CNN网络中进行训练

边框回归

##### 1.加入ROI pooling层

​	ROI pooling layer实际上是SPP-NET的一个精简版，SSP-NET对每个proposal使用了不同大小的金字塔映射，而ROI pooling layer只需要下采样到一个7x7的特征图。对于VGG16网络conv5_3有512个特征图，这样所有region proposal对应了一个7\*7\*512维度的特征向量作为全连接层的输入。

##### 2.将边框回归直接加入到了网络中，实现端到端

​	之前的R-CNN框架是分为提取proposl、CNN提取特征、SVM分类器分类这种割裂开的三个阶段，而**Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去region proposal提取阶段)。**

![](https://github.com/AnchoretY/images/blob/master/blog/Fast_R-CNN结构图2.png?raw=true)

##### 3.R-CNN和Fast R-CNN对比：

> R-CNN:许多候选框（比如两千个）-->CNN-->得到每个候选框的特征-->分类+回归
>
> Fast R-CNN：一张完整图片-->CNN-->得到每张候选框的特征-->分类+回归
>
> ​	Fast R-CNN相对于R-CNN的提速原因就在于：不过不像R-CNN把每个候选区域给深度网络提特征，而是**整张图提一次特征，再把候选框映射到conv5**上，而SPP只需要计算一次特征，剩下的只需要在conv5层上操作就可以了。

##### 4.存在问题

​	虽然不在不再需要对每个候选框进行卷积运算，但是**使用选择搜索算法进行候选框生成的过程也非常耗时**。



####（四）Faster R-CNN

**核心**

> ​	引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题

![](https://github.com/AnchoretY/images/blob/master/blog/Faster_R-CNN结构图.png?raw=true)

#####　RPN

​	首先在feature map上进行滑动的窗口，

![](https://github.com/AnchoretY/images/blob/master/blog/Faster_R-CNN四损失函数图.png?raw=true)

