---
zutitle: DBSCAN和KMeans相关资源和理解
date: 2018-09-23 15:41:35
tags: 机器学习
categories: 机器学习
---
DBSCAN和KMeans相关资源和理解
============

1.DBSCAN
--------------------------

DBSCAN是是一种典型的[密度聚类算法]()，算法主要的思是由密度可达关系导出最大的密度相连样本集合，将其作为一个类。
​    
> 主要参数：
>* 最小分类样本数 
>* 半径

>1. DBSCAN算法为有参数算法，聚类的最终结果很大程度上取决于参数的设定
>2. DBSCAN算法不需要指定聚类个数，聚类个数根据算法和数据情况自动获得

#### DBSCAN聚类过程

>1. 首先根据半径画每个点的邻域，当点的邻域内点的个数大于最小样本数时，该点位为核心对象（原始数据集重点的变为核心对象和一般点）
>2. 随机确定一个核心点作为初始点，将该初始点全部的最大密度相连的点作为一类。
>3. 将分好类样本从原始的样本集中除去，从新选择核心对象作为聚类中心，再进行2.3操作，直至全部核心对象都被分类

![image](https://github.com/Anchoret91/youdao_image/blob/master/dbscan.png?raw=true)

#### DBSCAN代码实现

    from sklearn.cluster import DBSCAN
    
    dbcscan = DBSCAN(min_samples=30,eps=1.8)
    predict = dbscan.fit_predict(imput)

2.K-Means
------------------------
KMeans是一种原始性聚类算法，算法主要思想是通过迭代过程把数据集划分为不同的类别，使得评价聚类性能的准则函数达到最优，从而使生成的每个聚类内紧凑，类间独立。
**这一算法不适合处理离散型数据，对连续性数据具有良好的效果**

>1. Kmeans为无参数算法，算法执行过程中不需要进行调参
>2. Kmeans算法需要指定聚类个数K，这在实际问题中是很难进行确定的

#### KMeans聚类过程
>1. 根据指定的K值随机寻找K个点作为初始中心，将其他样本分别分给这些中心
>2. 由分好的类计算均值作为其该类新的中心，重新对各个样本分到距离最近的中心，重复这一过程，直至中心不再变化

#### Kmeans代码实现
    from sklearn.cluster import KMeans
    
    kmeans = KMeans(n_clusters=8)
    predict = kmeans.fit_predict(input)


Kmeans、DBSCAN优缺点对比
--------------------------
DBSCAN的主要优点有：

　　　　1） 可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。

　　　　2） 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。

　　　　3） 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。

　　　　DBSCAN的主要缺点有：

　　　　1）如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。

　　　　2） 如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。

　　　　3） 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。


