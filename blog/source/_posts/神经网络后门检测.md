---
title: 神经网络后门检测
copyright: true
mathjax: true
date: 2021-02-23 10:07:55
tags:
categories:
---

概述：首页描述

![]()

<!--more-->

### 攻击现状分析

&emsp;&emsp;目前神经网络后门攻击主要分为trigger-driven攻击和clean-label攻击两种方式。trigger-driven攻击使用触发器来控制是否是否后门，使本可正常识别的样本附加上tigger以后来误导模型误判到指定类别。clean-label攻击在训练数据中进行投毒，再输入数据中加入扰动，从而使导致在其特征空间中产生错误的表示，从而影响类别判断。



#### Trigger

**相关论文**

- Badnets: Identifying vulnerabilities in the machine learning model supply chain.
- Targeted backdoor attacks on deep learning systems using data poisoning. 2017.
- Latent backdoor attacks on deep neural networks. 2019 ACM.
- Trojaning Attack on Neural Networks. **NDSS**.2018. 

**代表论文分析**

- [Trojaning Attack on Neural Networks](./神经网络中的后门攻击.md)



#### clean label

 **相关论文**

- Poison frogs! targeted clean-label poisoning attacks on neural networks. **NIPS**. 2018
- Transferable clean-label poisoning attacks on deep neural nets.**ICML**.2019

**代表论文分析**









##### 参考文献

- [Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks 论文阅读、复现及思考](https://blog.csdn.net/karmayh/article/details/90181384)
- 