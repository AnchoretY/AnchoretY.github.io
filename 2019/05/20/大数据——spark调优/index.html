<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.7.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"anchorety.github.io","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/search.xml"};
  </script>

  <meta name="description" content="Spark调优核心参数设置 num-executors 该参数一定被设置， 为当前Application生产指定个数的Executors 实际生产环境分配80个左右的Executorsexecutor-memory 与JVM OOM(内存溢出)紧密相关，很多时候甚至决定了spark运行的性能 实际生产环境下建议8GB左右 若运行在yarn上，内存占用量不超过yarn的内存资源的50%excutor">
<meta name="keywords" content="面试,大数据">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据——spark调优">
<meta property="og:url" content="https://anchorety.github.io/2019/05/20/大数据——spark调优/index.html">
<meta property="og:site_name" content="AnchoretY&#39;s blog">
<meta property="og:description" content="Spark调优核心参数设置 num-executors 该参数一定被设置， 为当前Application生产指定个数的Executors 实际生产环境分配80个左右的Executorsexecutor-memory 与JVM OOM(内存溢出)紧密相关，很多时候甚至决定了spark运行的性能 实际生产环境下建议8GB左右 若运行在yarn上，内存占用量不超过yarn的内存资源的50%excutor">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-05-20T03:43:35.249Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大数据——spark调优">
<meta name="twitter:description" content="Spark调优核心参数设置 num-executors 该参数一定被设置， 为当前Application生产指定个数的Executors 实际生产环境分配80个左右的Executorsexecutor-memory 与JVM OOM(内存溢出)紧密相关，很多时候甚至决定了spark运行的性能 实际生产环境下建议8GB左右 若运行在yarn上，内存占用量不超过yarn的内存资源的50%excutor">

<link rel="canonical" href="https://anchorety.github.io/2019/05/20/大数据——spark调优/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>大数据——spark调优 | AnchoretY's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AnchoretY's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://anchorety.github.io/2019/05/20/大数据——spark调优/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大数据——spark调优
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2019-05-20 09:39:03 / 修改时间：11:43:35" itemprop="dateCreated datePublished" datetime="2019-05-20T09:39:03+08:00">2019-05-20</time>
            </span>

          
            <span id="/2019/05/20/大数据——spark调优/" class="post-meta-item leancloud_visitors" data-flag-title="大数据——spark调优" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/05/20/大数据——spark调优/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/05/20/大数据——spark调优/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Spark调优核心参数设置"><a href="#Spark调优核心参数设置" class="headerlink" title="Spark调优核心参数设置"></a>Spark调优核心参数设置</h3><blockquote>
<p><strong>num-executors</strong> 该参数一定被设置， 为当前Application生产指定个数的Executors 实际生产环境分配<strong>80个左右</strong>的Executors<br><strong>executor-memory</strong> 与<strong>JVM OOM(内存溢出)</strong>紧密相关，很多时候甚至决定了spark运行的性能 实际生产环境下建议<strong>8GB左右</strong> 若运行在yarn上，内存占用量不超过yarn的内存资源的50%<br><strong>excutor-cores</strong> 决定了在Executor中能够<strong>并行执行的Task的个数</strong> 实际生产环境建议<strong>2~3个</strong> </p>
<p><strong>driver-memory</strong> 作为驱动，默认是1GB 生产环境一般设置4GB</p>
<p><strong>spark.default.parallelism</strong> 建议至少设置100个，<strong>官方推荐是num-executors*excutor-cores的2~3倍</strong><br><strong>spark.storage.memoryFraction</strong> 用于存储的比例默认占用60%，如果计算比较依赖于历史数据，则可以适当调高该参数，如果计算严重依赖于shuffle，则需要降低该比例<br><strong>spark.shuffle.memoryFraction</strong> 用于shuffle的内存比例，默认占用20% 如果计算严重依赖于shuffle,则需要提高该比例</p>
</blockquote>
<h3 id="spark生态的主要组件："><a href="#spark生态的主要组件：" class="headerlink" title="spark生态的主要组件："></a>spark生态的主要组件：</h3><blockquote>
<p>spark core，任务调度，内存管理，错误恢复<br>spark sql，结构化数据处理<br>spark streaming，流式计算<br>spark MLlib，机器学习库<br>GraphX,图计算</p>
</blockquote>
<h3 id="spark运行模式："><a href="#spark运行模式：" class="headerlink" title="spark运行模式："></a>spark运行模式：</h3><blockquote>
<ol>
<li>local模式</li>
<li>standalone模式，构建master+slave集群</li>
<li>Spark on Yarn模式</li>
<li>Spark on Mesos模式</li>
</ol>
</blockquote>
<h3 id="宽窄依赖"><a href="#宽窄依赖" class="headerlink" title="宽窄依赖"></a>宽窄依赖</h3><blockquote>
<p>1.窄依赖是1对1或1对多，宽依赖是多对1</p>
<p>2.窄依赖前一步map没有完全完成也可以进行下一步，在一个线程里完成不划分stage;宽依赖下一步需要依赖前一步的结果，划分stage</p>
<p>4.在传输上，窄依赖之间在一个stage内只需要做pipline，每个父RDD的分区只会传入到一个子RDD分区中，通常可以在一个节点内完成转换；宽依赖在stage做shuffle，需要在运行过程中将同一个父RDD的分区传入到不同的子RDD分区中，中间可能涉及多个节点之间的数据传输</p>
<p>3.容错上，窄依赖只需要重新计算子分区对应的负分区的RDD即可；宽依赖，在极端情况下所有负分区的RDD都要被计算</p>
</blockquote>
<h4 id="map­reduce中数据倾斜的原因-应该如何处理"><a href="#map­reduce中数据倾斜的原因-应该如何处理" class="headerlink" title="map­reduce中数据倾斜的原因?应该如何处理?"></a>map­reduce中数据倾斜的原因?应该如何处理?</h4><p>如何处理spark中的数据倾斜?</p>
<blockquote>
<p><strong>原因</strong>：在物理执行期间，RDD会被分为一系列的分区，每个分区都是整个数据集的子集。当spark调度并运行任务的时候，Spark会为每一个分区中的数据创建一个任务。大部分的任务处理的数据量差不多，但是有少部分的任务处理的数据量很大，因而Spark作业会看起来运行的十分的慢，从而产生<strong>数据倾斜</strong></p>
<p><strong>处理方式：</strong></p>
<p>  1.使用需要进行shuffle人工指定参数并行度</p>
<p>  2.进行数据的清洗,把发生倾斜的刨除,用单独的程序去算倾斜的key</p>
<p>  3.join的时候使用小数据join大数据时，换用map join</p>
<ol>
<li>尽量减少shuffle的次数</li>
</ol>
</blockquote>
<h3 id="Spark分区数设置"><a href="#Spark分区数设置" class="headerlink" title="Spark分区数设置"></a>Spark分区数设置</h3><blockquote>
<p><strong>1、分区数越多越好吗？</strong></p>
<p>不是的，分区数太多意味着任务数太多（一个partion对应一个任务），每次调度任务也是很耗时的，所以分区数太多会导致总体耗时增多。</p>
<p><strong>2、分区数太少会有什么影响？</strong></p>
<p>分区数太少的话，会导致一些结点没有分配到任务；另一方面，分区数少则每个分区要处理的数据量就会增大，从而对每个结点的内存要求就会提高；还有分区数不合理，会导致数据倾斜问题。</p>
<p><strong>3、合理的分区数是多少？如何设置？</strong></p>
<p>总核数=executor-cores * num-executor </p>
<p>一般合理的分区数设置为总核数的2~3倍</p>
</blockquote>
<h3 id="Worker、Master、Executor、Driver-4大组件"><a href="#Worker、Master、Executor、Driver-4大组件" class="headerlink" title="Worker、Master、Executor、Driver 4大组件"></a>Worker、Master、Executor、Driver 4大组件</h3><blockquote>
<p><strong>1.master和worker节点</strong></p>
<p>搭建spark集群的时候我们就已经设置好了master节点和worker节点，一个集群有一个master节点和多个worker节点。</p>
<p><strong>master节点常驻master守护进程，负责管理worker节点，我们从master节点提交应用。</strong></p>
<p><strong>worker节点常驻worker守护进程，与master节点通信，并且管理executor进程。</strong></p>
<p><strong>2.driver和executor进程</strong></p>
<p>driver进程就是应用的main()函数并且构建sparkContext对象，<strong>当我们提交了应用之后，便会启动一个对应的driver进程，driver本身会根据我们设置的参数占有一定的资源</strong>（主要指cpu core和memory）。下面说一说driver和executor会做哪些事。</p>
<p>driver可以运行在master上，也可以运行worker上（根据部署模式的不同）。<strong>driver首先会向集群管理者（standalone、yarn，mesos）申请spark应用所需的资源，也就是executor，然后集群管理者会根据spark应用所设置的参数在各个worker上分配一定数量的executor，每个executor都占用一定数量的cpu和memory</strong>。<strong>在申请到应用所需的资源以后，driver就开始调度和执行我们编写的应用代码了。driver进程会将我们编写的spark应用代码拆分成多个stage，每个stage执行一部分代码片段，并为每个stage创建一批tasks，然后将这些tasks分配到各个executor中执行。</strong></p>
<p>executor进程宿主在worker节点上，一个worker可以有多个executor。每个executor持有一个线程池，每个线程可以执行一个task，<strong>executor执行完task以后将结果返回给driver</strong>，每个executor执行的task都属于同一个应用。<strong>此外executor还有一个功能就是为应用程序中要求缓存的 RDD 提供内存式存储，RDD 是直接缓存在executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</strong></p>
<p>driver进程会将我们编写的spark应用代码拆分成多个stage，每个stage执行一部分代码片段，并为每个stage创建一批tasks，然后将这些tasks分配到各个executor中执行。</p>
</blockquote>
<h3 id="Spark是如何进行资源管理的？"><a href="#Spark是如何进行资源管理的？" class="headerlink" title="Spark是如何进行资源管理的？"></a>Spark是如何进行资源管理的？</h3><blockquote>
<p><strong>1）资源的管理和分配</strong> </p>
<p>资源的管理和分配，<strong>由Master和Worker来完成</strong>。</p>
<p><strong>Master给Worker分配资源， Master时刻知道Worker的资源状况。</strong> </p>
<p><strong>客户端向服务器提交作业，实际是提交给Master。</strong></p>
<p><strong>2）资源的使用</strong> </p>
<p>资源的使用，由Driver和Executor。程序运行时候，向Master请求资源。</p>
</blockquote>
<h3 id="Spark和mapreduce点的区别"><a href="#Spark和mapreduce点的区别" class="headerlink" title="Spark和mapreduce点的区别"></a>Spark和mapreduce点的区别</h3><blockquote>
<p>优点：</p>
<p>1.最大的区别在于.spark把用到的中间数据放入内存，而mapreduce需要通过HDFS从磁盘中取数据。</p>
<p>2.spark算子多，mapreduce只有map和reduce两种操作</p>
<p>缺点：</p>
<p>​    spark过度依赖内存计算，如果参数设置不当，内存不够时就会因频繁GC导致线程等待</p>
</blockquote>
<h3 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h3><blockquote>
<p><strong>RDD是一个只读的分布式弹性数据集</strong>，是spark的基本抽象</p>
<p><strong>主要特性：</strong></p>
<p>​    1.分布式。由多个partition组成，可能分布于多台机器，可<strong>并行计算</strong></p>
<p>​    2.高效的容错（弹性）。通过RDD之间的依赖关系重新计算丢失的分区</p>
<p>​    3.只读。不可变</p>
</blockquote>
<h3 id="RDD在spark中的运行流程？"><a href="#RDD在spark中的运行流程？" class="headerlink" title="RDD在spark中的运行流程？"></a>RDD在spark中的运行流程？</h3><blockquote>
<ol>
<li>创建RDD对象</li>
<li>sparkContext负责计算RDD之间的依赖关系，构建DAG</li>
<li>DAGScheduler负责把DAG分解成多个stage(shuffle stage和final stage)，每个stage中包含多个task，每个task会被TAskScheduler分发给WORKER上的Executor执行</li>
</ol>
</blockquote>
<h3 id="spark任务执行流程："><a href="#spark任务执行流程：" class="headerlink" title="spark任务执行流程："></a>spark任务执行流程：</h3><blockquote>
<ol>
<li>Driver端提交任务，向Master申请资源</li>
<li>Master与Worker进行RPC通信，让Work启动Executor</li>
<li>Executor启动反向注册Driver，通过Driver—Master—Worker—Executor得到Driver在哪里</li>
<li>Driver产生Task，提交给Executor中启动Task去真正的做计算</li>
</ol>
</blockquote>
<h3 id="spark是如何容错的？"><a href="#spark是如何容错的？" class="headerlink" title="spark是如何容错的？"></a>spark是如何容错的？</h3><blockquote>
<p><strong>主要采用Lineage(血统)机制来进行容错，但在某些情况下也需要使用RDD的checkpoint</strong></p>
<ol>
<li><p>对于窄依赖，只计算父RDD相关数据即可，窄依赖开销较小</p>
</li>
<li><p>对于宽依赖，需计算所有依赖的父RDD相关数据，会产生冗余计算，宽依赖开销较大。</p>
</li>
</ol>
<p>   在两种情况下，RDD需要加checkpoint</p>
<p>   1.DAG中的Lineage过长，如果重算，开销太大</p>
<p>   2.在宽依赖上Cheakpoint的收益更大</p>
</blockquote>
<h3 id="一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？"><a href="#一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？" class="headerlink" title="一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？"></a>一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？</h3><blockquote>
<p>task由分区决定，读取时候其实调用的是hadoop的split函数，根据HDFS的block来决定<br>每个job的并行度由core决定</p>
</blockquote>
<h3 id="cache与checkpoint的区别"><a href="#cache与checkpoint的区别" class="headerlink" title="cache与checkpoint的区别"></a>cache与checkpoint的区别</h3><blockquote>
<p>cache 和 checkpoint 之间有一个重大的区别，<strong>cache 将 RDD 以及 RDD 的血统(记录了这个RDD如何产生)缓存到内存中</strong>，当缓存的 RDD 失效的时候(如内存损坏)，<br>它们可以通过血统重新计算来进行恢复。但是 <strong>checkpoint 将 RDD 缓存到了 HDFS 中，同时忽略了它的血统(也就是RDD之前的那些依赖)</strong>。为什么要丢掉依赖？因为可以<strong>利用 HDFS 多副本特性保证容错</strong>！</p>
</blockquote>
<h3 id="reduceByKey和groupByKey的区别"><a href="#reduceByKey和groupByKey的区别" class="headerlink" title="reduceByKey和groupByKey的区别?"></a>reduceByKey和groupByKey的区别?</h3><blockquote>
<p><strong>如果能用reduceByKey,那就用reduceByKey</strong>.因为它<strong>会在map端,先进行本地combine,可以大大减少要传输到reduce端的数据量,减小网络传输的开销</strong>。</p>
<p>groupByKey的性能,相对来说要差很多,因为它<strong>不会在本地进行聚合</strong>,而<strong>是原封不动,把ShuffleMapTask的输出,拉取到ResultTask的内存中</strong>,所以这样的话,就会导致,所有的数据,都要进行网络传输从而导致网络传输性能开销非常大!</p>
</blockquote>
<h3 id="map和mapPartition的区别？"><a href="#map和mapPartition的区别？" class="headerlink" title="map和mapPartition的区别？"></a>map和mapPartition的区别？</h3><blockquote>
<p><strong>1.map是对rdd中的每一个元素进行操作；mapPartitions则是对rdd中的每个分区的迭代器进行操作</strong><br>如果是普通的map，比如一个partition中有1万条数据。ok，那么你的function要执行和计算1万次。使用MapPartitions操作之后，一个task仅仅会执行一次function，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。</p>
<p>2<strong>.如果在map过程中需要频繁创建额外的对象</strong>(例如将rdd中的数据通过jdbc写入数据库,map需要为每个元素<br>创建一个链接而mapPartition为每个partition创建一个链接),<strong>则mapPartitions效率比map高的多</strong>。</p>
<p>3.S<strong>parkSql或DataFrame默认会对程序进行mapPartition的优化。</strong></p>
<p>mapPartition<strong>缺点</strong>：<br>    <strong>一次性读入整个分区全部内容，分区数据太大会导致内存OOM</strong></p>
</blockquote>
<h3 id="详细说明一下GC对spark性能的影响-优化"><a href="#详细说明一下GC对spark性能的影响-优化" class="headerlink" title="详细说明一下GC对spark性能的影响?优化"></a>详细说明一下GC对spark性能的影响?优化</h3><blockquote>
<p><strong>GC会导致spark的性能降低</strong>。因为<strong>spark中的task运行时是工作线程,GC是守护线程</strong>,<strong>守护线程运行时,会让工作线程停止,所以GC运行的时候,会让Task停下来,这样会影响spark</strong></p>
<p>程序的运行速度,降低性能。<br>    默认情况下,<strong>Executor的内存空间分60%给RDD用来缓存,只分配40%给Task运行期间动态创建对象,这个内存有点小,很可能会发生full gc,</strong>因为内存小就会导致创建的对象很快把内存填满,然后就会GC了,就是<strong>JVM尝试找到不再被使用的对象进行回收,清除出内存空间</strong>。所以如果Task分配的内存空间小,就会频繁的发生GC,从而导致频繁的Task工作线程的停止,从而降低Spark应用程序的性能。</p>
<p><strong>优化方式</strong>：</p>
<p>​    1<strong>.增加executor内存</strong></p>
<p>​    2<strong>.可以用通过调整executor比例</strong>,比如将RDD缓存空间占比调整为40%,分配给Task的空间变为了60%,这样的话可以降低GC发生的频率   spark.storage.memoryFraction</p>
<p>​    2.<strong>使用Kryo序列化类库进行序列化</strong></p>
</blockquote>
<h3 id="为什么要使用广播变量？"><a href="#为什么要使用广播变量？" class="headerlink" title="为什么要使用广播变量？"></a>为什么要使用广播变量？</h3><blockquote>
<p><strong>当RDD的操作要使用driver中定义的变量时,每次都要把变量发送给worker节点一次,如果这个变量的数据很大的话,会产生很高的负载,导致执行效率低</strong>;<br><strong>使用广播变量可以高效的使一个很大的只读数据发送给多个worker节点,而且对每个worker节点只需要传输一次,每次操作时executor可以直接获取本地保存的数据副本,不需要多次传输</strong></p>
</blockquote>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>AnchoretY
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://anchorety.github.io/2019/05/20/大数据——spark调优/" title="大数据——spark调优">https://anchorety.github.io/2019/05/20/大数据——spark调优/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/面试/" rel="tag"># 面试</a>
              <a href="/tags/大数据/" rel="tag"># 大数据</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/05/18/机器学习——SMOTE算法/" rel="prev" title="机器学习——SMOTE算法">
      <i class="fa fa-chevron-left"></i> 机器学习——SMOTE算法
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/05/20/面试常见的计算机基础知识/" rel="next" title="面试常见的计算机基础知识">
      面试常见的计算机基础知识 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark调优核心参数设置"><span class="nav-text">Spark调优核心参数设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark生态的主要组件："><span class="nav-text">spark生态的主要组件：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark运行模式："><span class="nav-text">spark运行模式：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#宽窄依赖"><span class="nav-text">宽窄依赖</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map­reduce中数据倾斜的原因-应该如何处理"><span class="nav-text">map­reduce中数据倾斜的原因?应该如何处理?</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark分区数设置"><span class="nav-text">Spark分区数设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Worker、Master、Executor、Driver-4大组件"><span class="nav-text">Worker、Master、Executor、Driver 4大组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark是如何进行资源管理的？"><span class="nav-text">Spark是如何进行资源管理的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark和mapreduce点的区别"><span class="nav-text">Spark和mapreduce点的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是RDD"><span class="nav-text">什么是RDD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD在spark中的运行流程？"><span class="nav-text">RDD在spark中的运行流程？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark任务执行流程："><span class="nav-text">spark任务执行流程：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark是如何容错的？"><span class="nav-text">spark是如何容错的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？"><span class="nav-text">一个RDD的task数量是又什么决定？一个job能并行多少个任务是由什么决定的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cache与checkpoint的区别"><span class="nav-text">cache与checkpoint的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduceByKey和groupByKey的区别"><span class="nav-text">reduceByKey和groupByKey的区别?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#map和mapPartition的区别？"><span class="nav-text">map和mapPartition的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#详细说明一下GC对spark性能的影响-优化"><span class="nav-text">详细说明一下GC对spark性能的影响?优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么要使用广播变量？"><span class="nav-text">为什么要使用广播变量？</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="AnchoretY"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">AnchoretY</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">132</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/anchorety" title="GitHub → https://github.com/anchorety" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/yhk7520831104@gmail.com" title="E-Mail → yhk7520831104@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AnchoretY</span>
</div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='1' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>










<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'S7MlHMmpqsSeCmfOcq43iVAD-gzGzoHsz',
      appKey     : 'zItfNM4ps7umY5pL3gKAJiYX',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
